{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bicycle Crash analysis NEISS data 1999 to 2018\n",
    "## National Electronic Injury Surveillance System\n",
    "\n",
    "https://github.com/mrcorbett/MET_CS677_DataScienceWithPython/tree/master\n",
    "\n",
    "\n",
    "\"CPSCâ€™s National Electronic Injury Surveillance System (NEISS) is a national probability sample of hospitals in the U.S. and its territories. Patient information is collected from each NEISS hospital for every emergency visit involving an injury associated with consumer products.\"\n",
    "\n",
    "https://catalog.data.gov/dataset/cpscs-national-electronic-injury-surveillance-system-neiss\n",
    "https://www.cpsc.gov/cgibin/NEISSQuery/home.aspx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import calendar\n",
    "from code_id_translator import *\n",
    "from datetime import datetime\n",
    "import graphviz\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, fixed\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.pyplot as plt\n",
    "from neiss_backend import *\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, chi2, f_regression, mutual_info_regression\n",
    "from sklearn.feature_selection import SelectPercentile, SelectFpr, SelectFdr, SelectFwe, GenericUnivariateSelect\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz, plot_tree\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from time_based_graphs import *\n",
    "import xlrd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Includes():\n",
    "    TimeBasedGraphs = False\n",
    "    PearsonChiSquared = False\n",
    "    PythonCorr = False\n",
    "    LinearRegressionChi2 = False\n",
    "    LogisticRegression = False\n",
    "    GaussianNB = False\n",
    "    DecisionTree = True\n",
    "    HyperparameterTuning = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Selection of geographic areas called primary sampling units (PSU) that are defined within sampling strata. \n",
    "\n",
    "https://www.cdc.gov/nchs/nhis/singleton_psu.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the pickled neissYYYY.xlsx file\n",
    "\n",
    "convert_neiss_original_data_to_pckl.ipynb is used to create the pickled file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- If the neiss_data.pckl file exists read it as the data file.\n",
    "- Otherwise, raise an exception.\n",
    "\n",
    "See convert_neiss_original_data_to_pckl.ipynb for the creation of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/mcorbett/Boston University/MET_CS677_DataScienceWithPython/Project/data/NEISS/neiss_data.pckl  ... done!\n"
     ]
    }
   ],
   "source": [
    "neiss_pathname = os.getcwd() + '/data/NEISS'\n",
    "\n",
    "pckl_fname = neiss_pathname + '/neiss_data.pckl'\n",
    "if os.path.exists(pckl_fname):\n",
    "    print(\"Reading {}  ... \".format(pckl_fname), end=\"\")\n",
    "    dfNeiss = pickle.load( open( pckl_fname, \"rb\" ) )\n",
    "    print(\"done!\")\n",
    "else:\n",
    "    raise Exception(\n",
    "        'ERROR:  {} does not exist\\n  Use \"convert_neiss_original_data_to_pckl.ipynb\" to create the pckl file'.format(\n",
    "            pckl_fname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352927, 19)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNeiss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPSC_Case_Number</th>\n",
       "      <th>Treatment_Date</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Other_Race</th>\n",
       "      <th>Body_Part</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Other_Diagnosis</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>Location</th>\n",
       "      <th>Fire_Involvement</th>\n",
       "      <th>Product_1</th>\n",
       "      <th>Product_2</th>\n",
       "      <th>Narrative_1</th>\n",
       "      <th>Narrative_2</th>\n",
       "      <th>Stratum</th>\n",
       "      <th>PSU</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100001</td>\n",
       "      <td>1999-12-24</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3299</td>\n",
       "      <td>0</td>\n",
       "      <td>41 YR FEMALE FELL WHILE WALKING. DX: SEVERE MU...</td>\n",
       "      <td>/RIGHT BUTTOCKS &amp; BACK.</td>\n",
       "      <td>S</td>\n",
       "      <td>71</td>\n",
       "      <td>68.1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>100002</td>\n",
       "      <td>1999-12-27</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>611</td>\n",
       "      <td>0</td>\n",
       "      <td>80 YR MALE FELL IN BATHROOM/HE HIT RIGHT RIBS ...</td>\n",
       "      <td>DX: FRACTURED RIGHT RIBS-UPPER TRUNK</td>\n",
       "      <td>S</td>\n",
       "      <td>71</td>\n",
       "      <td>68.1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100003</td>\n",
       "      <td>1999-12-27</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1328</td>\n",
       "      <td>0</td>\n",
       "      <td>4 YR MALE HAD METAL LARGE WAGON WHEEL FALL &amp; H...</td>\n",
       "      <td>DX: CONTUSIN ON HEAD/NO LOC.</td>\n",
       "      <td>S</td>\n",
       "      <td>71</td>\n",
       "      <td>68.1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>100005</td>\n",
       "      <td>1999-12-28</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1205</td>\n",
       "      <td>0</td>\n",
       "      <td>CONTUSION EAR - STRUCK IN RIGHT EAR WITH BASKE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7</td>\n",
       "      <td>68.1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>100009</td>\n",
       "      <td>1999-12-28</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5031</td>\n",
       "      <td>0</td>\n",
       "      <td>SPRAIN THUMB - INJURED THUMB WHEN SNOWBOARDING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7</td>\n",
       "      <td>68.1086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CPSC_Case_Number Treatment_Date  Age  Sex  Race Other_Race  Body_Part  \\\n",
       "0            100001     1999-12-24   41    2   1.0          0         31   \n",
       "1            100002     1999-12-27   80    1   2.0          0         31   \n",
       "2            100003     1999-12-27    4    1   1.0          0         75   \n",
       "3            100005     1999-12-28   18    1   0.0        NaN         94   \n",
       "4            100009     1999-12-28   19    2   0.0        NaN         92   \n",
       "\n",
       "   Diagnosis Other_Diagnosis  Disposition  Location  Fire_Involvement  \\\n",
       "0         71             NaN            1         0                 0   \n",
       "1         57             NaN            1         0                 0   \n",
       "2         53             NaN            1         0                 0   \n",
       "3         53             NaN            1         0                 0   \n",
       "4         64             NaN            1         0                 0   \n",
       "\n",
       "   Product_1  Product_2                                        Narrative_1  \\\n",
       "0       3299          0  41 YR FEMALE FELL WHILE WALKING. DX: SEVERE MU...   \n",
       "1        611          0  80 YR MALE FELL IN BATHROOM/HE HIT RIGHT RIBS ...   \n",
       "2       1328          0  4 YR MALE HAD METAL LARGE WAGON WHEEL FALL & H...   \n",
       "3       1205          0  CONTUSION EAR - STRUCK IN RIGHT EAR WITH BASKE...   \n",
       "4       5031          0     SPRAIN THUMB - INJURED THUMB WHEN SNOWBOARDING   \n",
       "\n",
       "                            Narrative_2 Stratum  PSU   Weight  \n",
       "0               /RIGHT BUTTOCKS & BACK.       S   71  68.1086  \n",
       "1  DX: FRACTURED RIGHT RIBS-UPPER TRUNK       S   71  68.1086  \n",
       "2          DX: CONTUSIN ON HEAD/NO LOC.       S   71  68.1086  \n",
       "3                                   NaN       S    7  68.1086  \n",
       "4                                   NaN       S    7  68.1086  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNeiss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Neiss with column code dictionary from Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_codes_fname = neiss_pathname + '/column_codes.xlsx'\n",
    "column_dictionary = getColumnCodeDictionary(column_codes_fname)\n",
    "Neiss.setColumnCodeDictionary(column_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Code to take the Neiss dictionaries for column codes and write them out to the column_codes.xlsx file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "neiss = Neiss(dfNeiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352927, 19)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNeiss.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a categorical dataframe (with a subset of the overall data 3000 random rows)\n",
    "\n",
    "The dataframe is built of columns that are only categorical in nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFramePruner():\n",
    "    def __init__(self, dict_prune=dict(), max_output_rows=None, keep_end=True):\n",
    "        '''\n",
    "        Prune a dataframe based on a dictionary and the maximum number of output rows\n",
    "        \n",
    "        Args:\n",
    "          dict_prune  (dict):  Of the form {col_name : max_output_categories, ...}\n",
    "          max_output_rows (int):  If none, all rows are kept.  Otherwise, the dataframe is clipped to this number of rows maximum.\n",
    "          keep_end (bool):  True, max_output_rows is relative to the end of the dataframe.  False, from beginning.\n",
    "        '''\n",
    "        self.dict_prune = dict_prune\n",
    "        self.max_output_rows = max_output_rows\n",
    "        self.keep_end = keep_end\n",
    "\n",
    "    def _limitColumnCategoriesTo(df, column_name, num_categories):\n",
    "        '''\n",
    "         Get the top 'num_categories' most frequent names in self.df[column_name]\n",
    "\n",
    "         Args:\n",
    "             column_name (str):  The name of the column to limit the categories on\n",
    "             num_categories (int):  The maximum number of unique values to retain in 'column_name'\n",
    "        '''\n",
    "        selected = df[column_name].value_counts()[:num_categories].index.tolist()\n",
    "        return df[df[column_name].isin(selected)]\n",
    "\n",
    "    def prune(self, df):\n",
    "        for column_name in self.dict_prune.keys():\n",
    "            df = DataFramePruner._limitColumnCategoriesTo(df, column_name, self.dict_prune[column_name])\n",
    "\n",
    "        if None != self.max_output_rows:\n",
    "            if True == self.keep_end:\n",
    "                df = df[-self.max_output_rows : ]\n",
    "            else:\n",
    "                df = df[0 : self.max_output_rows]\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeissSubset():\n",
    "    def __init__(self, df, categories, dataframe_pruner=None):\n",
    "        self.df = df.copy()\n",
    "        self.categories = categories.copy()\n",
    "\n",
    "        self.df = self.df.xs(self.categories, axis=1)\n",
    "        self.df.dropna(inplace=True)\n",
    "        self.df['Race'] = [int(x) for x in self.df['Race']]\n",
    "        \n",
    "        if None != dataframe_pruner:\n",
    "            self.df = dataframe_pruner.prune(self.df)\n",
    "\n",
    "        self.updateCodeIdVariables()\n",
    "\n",
    "    def updateCodeIdVariables(self):\n",
    "        # Get the code ID translator for the dataframe\n",
    "        self.codeIdTranslator = CodeIdTranslatorDataFrame(self.df, self.categories)\n",
    "        self.codeIdTranslator.transformColumns()\n",
    "\n",
    "        # Get the code ID translators for the dataframe\n",
    "        currentState = self.codeIdTranslator.getState()\n",
    "\n",
    "        self.codeIdTranslator.setState('id')\n",
    "        self.dfIdToCode = self.codeIdTranslator.getDataFrame().copy()\n",
    "\n",
    "        self.codeIdTranslator.setState('code')\n",
    "        self.dfCodeToId = self.codeIdTranslator.getDataFrame().copy()\n",
    "\n",
    "        self.codeIdTranslator.setState(currentState)\n",
    "\n",
    "    def limitColumnCategoriesTo(self, column_name, num_categories):\n",
    "        '''\n",
    "         Get the top 'num_categories' most frequent names in self.df[column_name]\n",
    "         \n",
    "         Args:\n",
    "             column_name (str):  The name of the column to limit the categories on\n",
    "             num_categories (int):  The maximum number of unique values to retain in 'column_name'\n",
    "        '''\n",
    "        selected = self.df[column_name].value_counts()[:num_categories].index.tolist()\n",
    "        self.df = self.df[self.df[column_name].isin(selected)]\n",
    "        #self.updateCodeIdVariables()\n",
    "\n",
    "    def limitMaxRowsTo(self, num_rows):\n",
    "        self.df = self.df.sample(num_rows)\n",
    "        #self.updateCodeIdVariables()\n",
    "\n",
    "    def getDataFrame(self):\n",
    "        return self.df\n",
    "\n",
    "    def getCategories(self):\n",
    "        return self.categories\n",
    "    \n",
    "    def getCodeIdTranslator(self):\n",
    "        return self.codeIdTranslator\n",
    "    \n",
    "    def getIdToCodeDataframe(self):\n",
    "        return self.dfIdToCode\n",
    "    \n",
    "    def getCodeToIdDataframe(self):\n",
    "        return self.dfCodeToId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_choice = 'Diagnosis'\n",
    "\n",
    "max_output_rows = 1000000\n",
    "pruner = DataFramePruner(dict_prune={output_choice : 10}, max_output_rows=max_output_rows, keep_end=True)\n",
    "\n",
    "neissSubset = NeissSubset(dfNeiss,\n",
    "    categories=['Sex', 'Race', 'Body_Part', 'Diagnosis', 'Disposition', 'Location',\n",
    "    'Fire_Involvement', 'Product_1', 'Product_2', 'PSU', 'Stratum' ],\n",
    "    dataframe_pruner=pruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 11)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neissSubset.getDataFrame().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Body_Part</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>Location</th>\n",
       "      <th>Fire_Involvement</th>\n",
       "      <th>Product_1</th>\n",
       "      <th>Product_2</th>\n",
       "      <th>PSU</th>\n",
       "      <th>Stratum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>33328</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>396</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33329</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>580</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33331</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33332</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33333</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>519</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sex  Race  Body_Part  Diagnosis  Disposition  Location  \\\n",
       "33328    3     2         16         10            1         9   \n",
       "33329    3     2          5          5            1         2   \n",
       "33331    3     2          9         10            1         2   \n",
       "33332    2     2          6          2            1         2   \n",
       "33333    2     2         11          4            1         2   \n",
       "\n",
       "       Fire_Involvement  Product_1  Product_2  PSU  Stratum  \n",
       "33328                 1        396          1   17        4  \n",
       "33329                 1        580          1   17        4  \n",
       "33331                 1        165          1   17        4  \n",
       "33332                 1         79          1   17        4  \n",
       "33333                 1        519          1   17        4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neissSubset.getDataFrame().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the IdToCode and CodeToId translators for the neissSubset dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Body_Part</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>Location</th>\n",
       "      <th>Fire_Involvement</th>\n",
       "      <th>Product_1</th>\n",
       "      <th>Product_2</th>\n",
       "      <th>PSU</th>\n",
       "      <th>Stratum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>33328</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>396</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33329</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>580</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33331</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33332</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33333</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>519</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sex  Race  Body_Part  Diagnosis  Disposition  Location  \\\n",
       "33328    3     2         16         10            1         9   \n",
       "33329    3     2          5          5            1         2   \n",
       "33331    3     2          9         10            1         2   \n",
       "33332    2     2          6          2            1         2   \n",
       "33333    2     2         11          4            1         2   \n",
       "\n",
       "       Fire_Involvement  Product_1  Product_2  PSU  Stratum  \n",
       "33328                 1        396          1   17        4  \n",
       "33329                 1        580          1   17        4  \n",
       "33331                 1        165          1   17        4  \n",
       "33332                 1         79          1   17        4  \n",
       "33333                 1        519          1   17        4  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neissSubset.getIdToCodeDataframe().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Body_Part</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>Location</th>\n",
       "      <th>Fire_Involvement</th>\n",
       "      <th>Product_1</th>\n",
       "      <th>Product_2</th>\n",
       "      <th>PSU</th>\n",
       "      <th>Stratum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>33328</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1290</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33329</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1807</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33331</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>610</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33332</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>374</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1616</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sex  Race  Body_Part  Diagnosis  Disposition  Location  \\\n",
       "33328    2     1         82         71            1         9   \n",
       "33329    2     1         34         57            1         1   \n",
       "33331    2     1         38         71            1         1   \n",
       "33332    1     1         35         53            1         1   \n",
       "33333    1     1         76         56            1         1   \n",
       "\n",
       "       Fire_Involvement  Product_1  Product_2  PSU Stratum  \n",
       "33328                 0       1290          0   19       S  \n",
       "33329                 0       1807          0   19       S  \n",
       "33331                 0        610          0   19       S  \n",
       "33332                 0        374          0   19       S  \n",
       "33333                 0       1616          0   19       S  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "neissSubset.getCodeToIdDataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show time based graphs of male/female injuries - whole dataframe used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.TimeBasedGraphs:\n",
    "    stat_name = 'Sex'\n",
    "    date_name = 'Treatment_Date'\n",
    "\n",
    "    TimeBasedGraphs(dfNeiss, Neiss.getColumnDictionary(stat_name), date_name, stat_name).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions/Classes used for the python correlations and pearson chi squared correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHighCorrelations(df, dfCategoricalCorrMatrix, minValue):\n",
    "    '''\n",
    "    For each column in the dataframe determine which rows equal or exceed the minimum value\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame):    The original dataframe\n",
    "        dfCategoricalCorrMatrix  (list of (row_name, col_name) tuples): The categorical matrix\n",
    "        minValue (int):  The value the row/column cell must equal or exceed\n",
    "\n",
    "    Returns:\n",
    "      A list of tuples containing (row, column) where the value equalled or exceeded the minimum value\n",
    "    '''\n",
    "    high_correlations = []\n",
    "    for yIndex, y in enumerate(dfCategoricalCorrMatrix.index):\n",
    "        for xIndex, x in enumerate(dfCategoricalCorrMatrix.columns):\n",
    "            #if xIndex >= yIndex:\n",
    "            #    break\n",
    "\n",
    "            if (x != y) and (dfCategoricalCorrMatrix[y][x] > minValue):\n",
    "                Y = y\n",
    "                X = x\n",
    "                if len(df[X].unique()) > len(df[Y].unique()):\n",
    "                    # Keep the smallest item on the X axis\n",
    "                    Y, X = X, Y\n",
    "\n",
    "                if (Y, X) not in high_correlations:\n",
    "                    high_correlations.insert(-1, (Y, X))\n",
    "    high_correlations.sort()\n",
    "    return high_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserSelectableSwarmScatterPlots():\n",
    "    def __init__(self, high_correlations, code_id_translator):\n",
    "        self.button = widgets.Button(description=\"Click Me!\")\n",
    "        self.output = widgets.Output()\n",
    "        self.high_correlations = high_correlations\n",
    "        self.code_id_translator = code_id_translator\n",
    "\n",
    "    def show(self):\n",
    "        button = widgets.Button(description=\"Click Me!\")\n",
    "        output = widgets.Output()\n",
    "\n",
    "        #print(self.high_correlations.values)\n",
    "        select = self.high_correlations[0]\n",
    "        #print(select)\n",
    "        lCorrelations = ['{}, {}'.format(y, x) for y, x in self.high_correlations]\n",
    "        correlationDropDownSel = widgets.Dropdown(\n",
    "            options=lCorrelations,\n",
    "            value=lCorrelations[0],\n",
    "            description='correlations',\n",
    "            disabled=False,\n",
    "        )\n",
    "\n",
    "        typeDropDownSel = widgets.Dropdown(\n",
    "            options=['swarm', 'scatter'],\n",
    "            value='swarm',\n",
    "            description='plot_type',\n",
    "            disabled=False,\n",
    "        )\n",
    "\n",
    "        wHBox = widgets.HBox([correlationDropDownSel, typeDropDownSel])\n",
    "        wVBox = widgets.VBox([wHBox, button, output])\n",
    "\n",
    "        display(wVBox)\n",
    "\n",
    "        def on_button_clicked(b):\n",
    "            with output:\n",
    "                sel = correlationDropDownSel.value\n",
    "                (xSel, ySel) = [x.strip() for x in sel.split(',')]\n",
    "                print('-{}-, -{}-'.format(xSel, ySel))\n",
    "\n",
    "                correlations(self.code_id_translator, xSel, ySel, typeDropDownSel.value)\n",
    "\n",
    "                #sns.pairplot(dfSel, hue=xSel)\n",
    "\n",
    "        button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalMatrixHeatMap:\n",
    "    def __init__(self, title, dfCategoricalMatrix):\n",
    "        self.title = title\n",
    "        self.dfCategoricalMatrix = dfCategoricalMatrix\n",
    "\n",
    "    def show(self, figsize=(10, 10)):\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "        g = sns.heatmap(self.dfCategoricalMatrix, annot=True, linewidths=0.4, ax=ax)\n",
    "        g.set_title(self.title)\n",
    "\n",
    "        # Fix the top and bottom margins of the heatmap\n",
    "        bottom_y, top_y = plt.ylim() \n",
    "        bottom_y += 0.5 \n",
    "        top_y -= 0.5 \n",
    "        plt.ylim(bottom_y, top_y)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python (pandas.DataFrame.corr) - dataframe subset used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.PythonCorr:\n",
    "    methods = {\n",
    "        'pearson' : 'Pearson R Correlation (parametric)',  # not good for categorical data\n",
    "            # For pearson:\n",
    "            # both variables should be normally distributed\n",
    "            # There should be no significant outliers\n",
    "            # Each variable should be continuous\n",
    "            # The two variables have a linear relationship\n",
    "            # The observations are paired observations.\n",
    "            # Should support homoscedascity.  Homoscedascity simply refers to â€˜equal variancesâ€™.\n",
    "        'kendall' : 'Kendall Tau-b rank correlation (non-parametric)',\n",
    "            # The variables are measured on an ordinal or continuous scale.\n",
    "            # Desirable if your data appears to follow a monotonic relationship.\n",
    "        'spearman' : 'Spearman rank correlation (non-parametric)'\n",
    "            # Does not assume that both datasets are normally distributed\n",
    "        }\n",
    "\n",
    "    dfCategoricalMatrices = {}\n",
    "    for key in methods.keys():\n",
    "        dfCategoricalMatrices[key] = neissSubset.getDataFrame().corr(method = key)\n",
    "        heatMap = CategoricalMatrixHeatMap(methods[key], dfCategoricalMatrices[key])\n",
    "        heatMap.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if True == Includes.PythonCorr:\n",
    "#    for key in dfCategoricalMatrices.keys():\n",
    "#        print('{}:\\n{}'.format(key, dfCategoricalMatrices))\n",
    "#        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.PythonCorr:\n",
    "    highCorrelationsPythonCorr = getHighCorrelations(\n",
    "        neissSubset.getDataFrame(),\n",
    "        dfCategoricalMatrices['spearman'],\n",
    "        0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if True == Includes.PythonCorr:\n",
    "#    for n in highCorrelationsPythonCorr:\n",
    "#        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.PythonCorr:\n",
    "    plots = UserSelectableSwarmScatterPlots(highCorrelationsPythonCorr, neissSubset.getCodeIdTranslator())\n",
    "    plots.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analysis: The pandas.DataFrame.corr method is not that great when used with categorical data given an output with many categories. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PearsonChiSquared - dataframe subset used\n",
    "\n",
    "https://machinelearningmastery.com/chi-squared-test-for-machine-learning/\n",
    "\n",
    "'The Pearsonâ€™s chi-squared statistical hypothesis is an example of a test for independence between categorical variables.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.PearsonChiSquared:\n",
    "    pearsonChiSquared = PearsonChiSquared(neissSubset.getDataFrame())\n",
    "    dfPersonChiSquaredCategoricalCorrMatrix = pearsonChiSquared.getCorrMatrixDataframe(neissSubset.getCategories())\n",
    "    #print(dfCategoricalCorrMatrix.head())\n",
    "\n",
    "    heatMap = CategoricalMatrixHeatMap('Pearson Chi Squared', dfPersonChiSquaredCategoricalCorrMatrix)\n",
    "    heatMap.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.PearsonChiSquared:\n",
    "    highCorrelationsPearsonChiSquared = getHighCorrelations(\n",
    "        neissSubset.getDataFrame(),\n",
    "        dfPersonChiSquaredCategoricalCorrMatrix,\n",
    "        0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if True == Includes.PearsonChiSquared:\n",
    "#    for n in highCorrelationsPearsonChiSquared:\n",
    "#        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.PearsonChiSquared:\n",
    "    plots = UserSelectableSwarmScatterPlots(highCorrelationsPearsonChiSquared, neissSubset.getCodeIdTranslator())\n",
    "    plots.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analysis:  Pearson ChiSquared is a better measure of correlation between categorical data than the three python functions shown below (used with pandas.DataFrame.corr):\n",
    "\n",
    "    'pearson' : 'Pearson R Correlation (parametric)',  # not good for categorical data\n",
    "    \n",
    "    'kendall' : 'Kendall Tau-b rank correlation (non-parametric)'\n",
    "    \n",
    "    'spearman' : 'Spearman rank correlation (non-parametric)'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression (using chi2 & KBest) - dataframe subset used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html\n",
    "\n",
    "- f_classif:  ANOVA F-value between label/feature for classification tasks.\n",
    "\n",
    "- mutual_info_classif: Mutual information for a discrete target.\n",
    "\n",
    "- chi2:  Chi-squared stats of non-negative features for classification tasks.\n",
    "\n",
    "- f_regression:  F-value between label/feature for regression tasks.\n",
    "\n",
    "- mutual_info_regression:  Mutual information for a continuous target.\n",
    "    \n",
    "- SelectPercentile:  Select features based on percentile of the highest scores.\n",
    "\n",
    "- SelectFpr:  Select features based on a false positive rate test.\n",
    "\n",
    "- SelectFdr:  Select features based on an estimated false discovery rate.\n",
    "\n",
    "- SelectFwe:  Select features based on family-wise error rate.\n",
    "\n",
    "- GenericUnivariateSelect:  Univariate feature selector with configurable mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.LinearRegressionChi2:\n",
    "    class WorkingLinearRegressionChi2():\n",
    "        def __init__(self, outputFeature, categories, dfIdToCode, k_features=2):\n",
    "            self.outputFeature = outputFeature\n",
    "            self.categories = categories.copy()\n",
    "            self.dfKBest = dfIdToCode.copy()\n",
    "        \n",
    "            self.categories.remove(self.outputFeature)\n",
    "\n",
    "            self.y = self.dfKBest[self.outputFeature]\n",
    "            self.selector = SelectKBest(chi2, k=k_features)\n",
    "            self.selector.fit(self.dfKBest[self.categories].values, self.y)\n",
    "            self.selector.get_support()\n",
    "\n",
    "            self.selected_columns = np.asarray(self.categories)[self.selector.get_support()]\n",
    "            self.X = self.dfKBest[self.selected_columns]\n",
    "    \n",
    "            \n",
    "        def plot_scatter(X,Y,R=None):\n",
    "            plt.scatter(X, Y, s=32, marker='o', facecolors='none', edgecolors='k')\n",
    "            if R is not None:\n",
    "                plt.scatter(X, R, color='red', linewidth=0.5)\n",
    "            plt.show()  \n",
    "\n",
    "        def showShape(self):\n",
    "            print('X.shape={}'.format(self.X.shape))\n",
    "            print()\n",
    "\n",
    "        def showSelectedColumns(self):\n",
    "            print('selected_columns={}'.format(self.selected_columns))\n",
    "            print()\n",
    "\n",
    "        def showSelectorScores(self):\n",
    "            print('selector.scores_={}'.format(self.selector.scores_))\n",
    "            print()\n",
    "\n",
    "        def showSelectorSupport(self):\n",
    "            print('selector.get_support()={}'.format(self.selector.get_support()))\n",
    "            print()\n",
    "\n",
    "        def showPlots(self):\n",
    "            for category in self.X:\n",
    "                print('x=', category)\n",
    "                x = np.asarray(self.dfKBest[category]).reshape(-1, 1)\n",
    "                regressor = LinearRegression(normalize=True).fit(x, self.y)\n",
    "                y_pred    = regressor.predict(x)\n",
    "                WorkingLinearRegressionChi2.plot_scatter(x, self.y, y_pred)\n",
    "                print(\"R-squared score: {:.4f}\".format(r2_score(self.y, y_pred)))\n",
    "                print()\n",
    "                print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.LinearRegressionChi2:\n",
    "    linearRegressionChi2 = WorkingLinearRegressionChi2(\n",
    "        output_choice,\n",
    "        neissSubset.getCategories(),\n",
    "        neissSubset.getIdToCodeDataframe(),\n",
    "        k_features=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.LinearRegressionChi2:\n",
    "    linearRegressionChi2.showShape()\n",
    "    linearRegressionChi2.showSelectedColumns()\n",
    "    linearRegressionChi2.showSelectorScores()\n",
    "    linearRegressionChi2.showSelectorSupport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "Todo_log_regression_change_x_y_to_strings"
    ]
   },
   "outputs": [],
   "source": [
    "if True == Includes.LinearRegressionChi2:\n",
    "    linearRegressionChi2.showPlots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analysis:  The data does not follow a linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkingHeatmap():\n",
    "    '''\n",
    "    Plots a seaborn fixing the edges of the plot\n",
    "    '''\n",
    "\n",
    "    def __init__(self, x_label, y_label,\n",
    "                 title='WorkingHeatmap',\n",
    "                 y_bottom_adjust=-1.5, y_top_adjust=-0.5,\n",
    "                 x_left_adjust=None, x_right_adjust=None,\n",
    "                 normalize_columns=False):\n",
    "        self.x_label            = x_label\n",
    "        self.y_label            = y_label\n",
    "        self.title              = title\n",
    "        self.y_bottom_adjust    = y_bottom_adjust\n",
    "        self.y_top_adjust       = y_top_adjust\n",
    "        self.x_left_adjust      = x_left_adjust\n",
    "        self.x_right_adjust     = x_right_adjust\n",
    "        self.normalize_columns  = normalize_columns\n",
    "\n",
    "    def plot(self,\n",
    "        data, vmin=None, vmax=None, cmap=None, center=None, robust=False,\n",
    "        annot=None, fmt='.2g', annot_kws=None, linewidths=0, linecolor='white',\n",
    "        cbar=True, cbar_kws=None, cbar_ax=None, square=False, xticklabels='auto',\n",
    "        yticklabels='auto', mask=None, ax=None, **kwargs):\n",
    "\n",
    "        if type(data) != pd.DataFrame:\n",
    "            data = pd.DataFrame(data)\n",
    "\n",
    "        dN = data\n",
    "        if True == self.normalize_columns:\n",
    "            dT = data.copy()\n",
    "            dS = dT.sum(axis=0)[:, np.newaxis]\n",
    "            dN = dT.astype('float') / dS.T.astype('float')\n",
    "\n",
    "\n",
    "        g = sns.heatmap(\n",
    "            dN, vmin, vmax, cmap, center, robust,\n",
    "            annot, fmt, annot_kws, linewidths, linecolor,\n",
    "            cbar, cbar_kws, cbar_ax, square, xticklabels,\n",
    "            yticklabels, mask, ax, **kwargs)\n",
    "        g.set_title(self.title)\n",
    "        ax.set_xlabel(self.x_label)\n",
    "        ax.set_ylabel(self.y_label)\n",
    "        \n",
    "        if self.y_bottom_adjust or self.y_top_adjust or self.x_left_adjust or self.x_right_adjust:\n",
    "\n",
    "            if self.y_bottom_adjust or self.y_top_adjust:\n",
    "                bottom_y, top_y = ax.get_ylim() \n",
    "\n",
    "                if self.y_bottom_adjust:\n",
    "                    bottom_y += self.y_bottom_adjust\n",
    "\n",
    "                if self.y_top_adjust:\n",
    "                    top_y += self.y_top_adjust\n",
    "\n",
    "                ax.set_ylim(bottom=bottom_y, top=top_y)\n",
    "\n",
    "            if self.x_left_adjust or self.x_right_adjust:\n",
    "                left_x, right_x = ax.get_xlim() \n",
    "\n",
    "                if self.x_left_adjust:\n",
    "                    left_x += self.x_left_adjust\n",
    "                    \n",
    "                if self.x_right_adjust:\n",
    "                    right_x += self.x_right_adjust\n",
    "\n",
    "                ax.set_xlim(left=left_x, right=right_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.LogisticRegression:\n",
    "    class WorkingLogisticRegression():\n",
    "        '''\n",
    "        Based loosly on:  https://acadgild.com/blog/logistic-regression-multiclass-classification\n",
    "        '''\n",
    "        def __init__(self, outputFeature, categories, dfIdToCode, codeIdTranslator, max_iter=5000):\n",
    "            self.outputFeature = outputFeature\n",
    "            self.categories = categories.copy()\n",
    "            self.df = dfIdToCode.copy()\n",
    "            self.codeIdTranslator = codeIdTranslator\n",
    "        \n",
    "            self.categories.remove(self.outputFeature)\n",
    "    \n",
    "            self.inputs = self.df[self.categories]\n",
    "            self.output = self.df[self.outputFeature]\n",
    "            \n",
    "            self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(\n",
    "                self.inputs, self.output, test_size=1/7.0, random_state=122)\n",
    "\n",
    "            # Standardize the data\n",
    "            scaler = StandardScaler()\n",
    "            \n",
    "            # Fit on training set only.\n",
    "            scaler.fit(self.x_train)\n",
    "\n",
    "            # Apply transform to both the training set and the test set.\n",
    "            self.x_train = scaler.transform(self.x_train)\n",
    "            self.x_test = scaler.transform(self.x_test)\n",
    "\n",
    "            # Fit the model\n",
    "            # For multiclass problems, only â€˜newton-cgâ€™, â€˜sagâ€™, â€˜sagaâ€™ and â€˜lbfgsâ€™ handle multinomial loss.\n",
    "            self.model = LogisticRegression(solver = 'newton-cg', multi_class='multinomial', max_iter=max_iter)\n",
    "            self.model.fit(self.x_train, self.y_train)\n",
    "\n",
    "            # Validate the fitting\n",
    "            # use the model to make predictions with the test data\n",
    "            self.y_pred = self.model.predict(self.x_test)\n",
    "\n",
    "            self.probs = self.model.predict_proba(self.x_test)\n",
    "            test_score = self.model.score(self.x_test, self.y_test)\n",
    "            print('test_score =', test_score)\n",
    "\n",
    "            # how did our model perform?\n",
    "            self.count_misclassified = (self.y_test != self.y_pred).sum()\n",
    "            self.accuracy = metrics.accuracy_score(self.y_test, self.y_pred)\n",
    "\n",
    "            self.confusion_matrix = metrics.confusion_matrix(self.y_test, self.y_pred)\n",
    "\n",
    "            # Create predicted versus actual dataframe\n",
    "            target_names = self.output.unique()\n",
    "\n",
    "            target_dict = column_dictionary[self.outputFeature]\n",
    "\n",
    "            dfTest = pd.DataFrame(self.y_test, columns=[self.outputFeature])\n",
    "            self.codeIdTranslator._transform(dfTest, 'idToCode', self.outputFeature)\n",
    "            y_test = [target_dict[x] for x in dfTest[self.outputFeature]]\n",
    "            self.y_test = y_test\n",
    "            #print('y_test={}'.format( np.sort(np.unique(y_test)) ))\n",
    "            \n",
    "            dfPred = pd.DataFrame(self.y_pred, columns=[self.outputFeature])\n",
    "            self.codeIdTranslator._transform(dfPred, 'idToCode', self.outputFeature)\n",
    "            y_pred = [target_dict[x] for x in dfPred[self.outputFeature]]\n",
    "            #print('y_pred={}'.format( np.sort(np.unique(y_pred)) ))\n",
    "\n",
    "            dfTargetNames = pd.DataFrame(target_names, columns=[self.outputFeature])\n",
    "            self.codeIdTranslator._transform(dfTargetNames, 'idToCode', self.outputFeature)\n",
    "            target_names =  [target_dict[x] for x in dfTargetNames[self.outputFeature]]\n",
    "            #print('target_names={}'.format( np.sort(np.unique(target_names)) ))\n",
    "\n",
    "            self.dfPredictedVersusActual = pd.DataFrame(self.probs, columns=target_names).round(4)\n",
    "            self.dfPredictedVersusActual.insert(0, 'target_class',    y_test)\n",
    "            self.dfPredictedVersusActual.insert(1, 'predicted_class', y_pred)\n",
    "            \n",
    "        def showAccuracy(self):\n",
    "            print('Accuracy: {:.2f}'.format(self.accuracy))\n",
    "\n",
    "        def showMissclassifiedSamples(self):\n",
    "            print('Misclassified samples: {} out of {}'.format(self.count_misclassified, len(self.y_test)))\n",
    "\n",
    "        def showConfusionMatrix(self):\n",
    "            labels=np.unique(self.y_test)\n",
    "            fig, ax = plt.subplots(figsize=(14, 14))\n",
    "\n",
    "            heatmap = WorkingHeatmap(title='WorkingLogisticRegression',\n",
    "                x_label='actual', y_label='predicted',\n",
    "                y_bottom_adjust=0.5, y_top_adjust=-0.5,\n",
    "                normalize_columns=True)\n",
    "\n",
    "            # This sets the yticks \"upright\" with 0, as opposed to sideways with 90.\n",
    "            plt.yticks(rotation=0)  # does not appear to be working...\n",
    "\n",
    "            heatmap.plot(\n",
    "                self.confusion_matrix.T, square=True, annot=True, fmt='.2f', cbar=False,\n",
    "                ax=ax, xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "            plt.show() \n",
    "\n",
    "        def getPredictedVersusActualDataframe(self):\n",
    "            #state = self.codeIdTranslator.getState()\n",
    "            return self.dfPredictedVersusActual\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.LogisticRegression:\n",
    "    logisticRegression = WorkingLogisticRegression(\n",
    "        output_choice,\n",
    "        neissSubset.getCategories(),\n",
    "        neissSubset.getIdToCodeDataframe(),    # neissSubset.getIdToCodeDataframe()[0:1500]\n",
    "        neissSubset.getCodeIdTranslator(),\n",
    "        max_iter=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.LogisticRegression:\n",
    "    logisticRegression.showMissclassifiedSamples()\n",
    "    logisticRegression.showAccuracy()\n",
    "    logisticRegression.showConfusionMatrix()\n",
    "    dfPredictedVersusActual = logisticRegression.getPredictedVersusActualDataframe()\n",
    "    display(dfPredictedVersusActual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analysis:  The data does not follow a logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes (GaussianNB) - dataframe subset used\n",
    "\n",
    "\n",
    "Can perform online updates to model parameters via partial_fit method. \n",
    "\n",
    "For details on algorithm used to update feature means and variance online, \n",
    "\n",
    "see Stanford CS tech report STAN-CS-79-773 by Chan, Golub, and LeVeque:\n",
    "\n",
    "\n",
    "http://i.stanford.edu/pub/cstr/reports/cs/tr/79/773/CS-TR-79-773.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.GaussianNB:\n",
    "    class WorkingGaussianNB():\n",
    "        def __init__(self, outputFeature, categories, dfIdToCode, codeIdTranslator, verbose=False):\n",
    "            self.outputFeature = outputFeature\n",
    "            self.categories = categories.copy()\n",
    "            self.df = dfIdToCode.copy()\n",
    "            self.codeIdTranslator = codeIdTranslator\n",
    "    \n",
    "            self.categories.remove(outputFeature)\n",
    "            # print('categories=', self.categories)\n",
    "            \n",
    "            # Build the Label encoder\n",
    "            self.le = {}\n",
    "            for col in self.df.columns:\n",
    "                self.le[col] = preprocessing.LabelEncoder()\n",
    "                self.le[col].fit(self.df[col].unique())\n",
    "\n",
    "                if True == verbose:\n",
    "                    print('{0:12s} => {1}'.format(col, self.le[col].classes_))\n",
    "\n",
    "            self.y_test = self.df[self.outputFeature]\n",
    "            self.y_labels = self.columnOutputValueIdToString(self.y_test.unique(), self.outputFeature)\n",
    "\n",
    "        def columnOutputValueIdToString(self, y_values, column_name):\n",
    "            target_dict = column_dictionary[column_name]\n",
    "\n",
    "            dfValues = pd.DataFrame(y_values, columns=[column_name])\n",
    "            self.codeIdTranslator._transform(dfValues, 'idToCode', column_name)\n",
    "            return [target_dict[x] for x in dfValues[column_name]]\n",
    "\n",
    "        def showPredicted(self):\n",
    "            print(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\"\n",
    "                  .format(\n",
    "                      self.df.shape[0],\n",
    "                      (self.y_test != self.y_pred).sum(),\n",
    "                      100*(1-(self.y_test != self.y_pred).sum()/self.df.shape[0])\n",
    "            ))\n",
    "\n",
    "        def showConfusionMatrix(self):\n",
    "            fig, ax = plt.subplots(figsize=(14, 14))\n",
    "\n",
    "            heatmap = WorkingHeatmap(title='WorkingGaussianNB',\n",
    "                x_label='true label', y_label='predicted label',\n",
    "                y_bottom_adjust=0.5, y_top_adjust=-0.5,\n",
    "                normalize_columns=True)\n",
    "        \n",
    "            # This sets the yticks \"upright\" with 0, as opposed to sideways with 90.\n",
    "            #plt.yticks(rotation=0)  # does not appear to be working...\n",
    "\n",
    "            heatmap.plot(\n",
    "                self.confusion_matrix.T, square=True, annot=True, fmt='.2f', cbar=False,\n",
    "                ax=ax, xticklabels=self.y_labels, yticklabels=self.y_labels)\n",
    "\n",
    "            plt.show() \n",
    "\n",
    "\n",
    "        def trainClassifier(self, show_predicted_versus_actual=True, show_confusion_matrices=True):\n",
    "            # Drop categories with low scores\n",
    "            categories = self.categories\n",
    "            df = self.df\n",
    "\n",
    "            # Train classifier\n",
    "            gnb = GaussianNB()\n",
    "            gnb.fit(\n",
    "                df[categories].values,\n",
    "                df[self.outputFeature])\n",
    "\n",
    "            y_pred = gnb.predict(self.df[categories])\n",
    "            self.y_pred = y_pred\n",
    "\n",
    "            self.confusion_matrix = metrics.confusion_matrix(self.y_test, self.y_pred,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.GaussianNB:\n",
    "    gaussianNB = WorkingGaussianNB(\n",
    "        output_choice,\n",
    "        neissSubset.getCategories(),\n",
    "        neissSubset.getIdToCodeDataframe(),\n",
    "        neissSubset.getCodeIdTranslator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.GaussianNB:\n",
    "    gaussianNB.trainClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.GaussianNB:\n",
    "    gaussianNB.showPredicted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.GaussianNB:\n",
    "    gaussianNB.showConfusionMatrix()\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
