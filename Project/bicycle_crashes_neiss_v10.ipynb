{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bicycle Crash analysis NEISS data 1999 to 2018\n",
    "## National Electronic Injury Surveillance System\n",
    "\n",
    "https://github.com/mrcorbett/MET_CS677_DataScienceWithPython/tree/master\n",
    "\n",
    "\n",
    "\"CPSC’s National Electronic Injury Surveillance System (NEISS) is a national probability sample of hospitals in the U.S. and its territories. Patient information is collected from each NEISS hospital for every emergency visit involving an injury associated with consumer products.\"\n",
    "\n",
    "https://catalog.data.gov/dataset/cpscs-national-electronic-injury-surveillance-system-neiss\n",
    "https://www.cpsc.gov/cgibin/NEISSQuery/home.aspx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import calendar\n",
    "from code_id_translator import *\n",
    "from datetime import datetime\n",
    "import graphviz\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, fixed\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.pyplot as plt\n",
    "from neiss_backend import *\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz, plot_tree\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from time_based_graphs import *\n",
    "import xlrd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Includes():\n",
    "    TimeBasedGraphs = False\n",
    "    PearsonChiSquared = False\n",
    "    PythonCorr = False\n",
    "    GaussianNB = True\n",
    "    LinearRegressionChi2 = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Selection of geographic areas called primary sampling units (PSU) that are defined within sampling strata. \n",
    "\n",
    "https://www.cdc.gov/nchs/nhis/singleton_psu.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the pickled neissYYYY.xlsx file\n",
    "\n",
    "xlsx_to_pckl.ipynb is used to create the pickled file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- If the neiss_data.pckl file exists read it as the data file.\n",
    "- Otherwise, raise an exception.\n",
    "\n",
    "See xlsx_to_pckl.ipynb for the creation of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/mcorbett/Boston University/MET_CS677_DataScienceWithPython/Project/data/NEISS/neiss_data.pckl  ... done!\n"
     ]
    }
   ],
   "source": [
    "neiss_pathname = os.getcwd() + '/data/NEISS'\n",
    "\n",
    "pckl_fname = neiss_pathname + '/neiss_data.pckl'\n",
    "if os.path.exists(pckl_fname):\n",
    "    print(\"Reading {}  ... \".format(pckl_fname), end=\"\")\n",
    "    dfNeiss = pickle.load( open( pckl_fname, \"rb\" ) )\n",
    "    print(\"done!\")\n",
    "else:\n",
    "    raise Exception('ERROR:  {} does not exist'.format(pckl_fname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352927, 19)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNeiss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPSC_Case_Number</th>\n",
       "      <th>Treatment_Date</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Other_Race</th>\n",
       "      <th>Body_Part</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Other_Diagnosis</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>Location</th>\n",
       "      <th>Fire_Involvement</th>\n",
       "      <th>Product_1</th>\n",
       "      <th>Product_2</th>\n",
       "      <th>Narrative_1</th>\n",
       "      <th>Narrative_2</th>\n",
       "      <th>Stratum</th>\n",
       "      <th>PSU</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100001</td>\n",
       "      <td>1999-12-24</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3299</td>\n",
       "      <td>0</td>\n",
       "      <td>41 YR FEMALE FELL WHILE WALKING. DX: SEVERE MU...</td>\n",
       "      <td>/RIGHT BUTTOCKS &amp; BACK.</td>\n",
       "      <td>S</td>\n",
       "      <td>71</td>\n",
       "      <td>68.1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>100002</td>\n",
       "      <td>1999-12-27</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>611</td>\n",
       "      <td>0</td>\n",
       "      <td>80 YR MALE FELL IN BATHROOM/HE HIT RIGHT RIBS ...</td>\n",
       "      <td>DX: FRACTURED RIGHT RIBS-UPPER TRUNK</td>\n",
       "      <td>S</td>\n",
       "      <td>71</td>\n",
       "      <td>68.1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100003</td>\n",
       "      <td>1999-12-27</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1328</td>\n",
       "      <td>0</td>\n",
       "      <td>4 YR MALE HAD METAL LARGE WAGON WHEEL FALL &amp; H...</td>\n",
       "      <td>DX: CONTUSIN ON HEAD/NO LOC.</td>\n",
       "      <td>S</td>\n",
       "      <td>71</td>\n",
       "      <td>68.1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>100005</td>\n",
       "      <td>1999-12-28</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1205</td>\n",
       "      <td>0</td>\n",
       "      <td>CONTUSION EAR - STRUCK IN RIGHT EAR WITH BASKE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7</td>\n",
       "      <td>68.1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>100009</td>\n",
       "      <td>1999-12-28</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5031</td>\n",
       "      <td>0</td>\n",
       "      <td>SPRAIN THUMB - INJURED THUMB WHEN SNOWBOARDING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7</td>\n",
       "      <td>68.1086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CPSC_Case_Number Treatment_Date  Age  Sex  Race Other_Race  Body_Part  \\\n",
       "0            100001     1999-12-24   41    2   1.0          0         31   \n",
       "1            100002     1999-12-27   80    1   2.0          0         31   \n",
       "2            100003     1999-12-27    4    1   1.0          0         75   \n",
       "3            100005     1999-12-28   18    1   0.0        NaN         94   \n",
       "4            100009     1999-12-28   19    2   0.0        NaN         92   \n",
       "\n",
       "   Diagnosis Other_Diagnosis  Disposition  Location  Fire_Involvement  \\\n",
       "0         71             NaN            1         0                 0   \n",
       "1         57             NaN            1         0                 0   \n",
       "2         53             NaN            1         0                 0   \n",
       "3         53             NaN            1         0                 0   \n",
       "4         64             NaN            1         0                 0   \n",
       "\n",
       "   Product_1  Product_2                                        Narrative_1  \\\n",
       "0       3299          0  41 YR FEMALE FELL WHILE WALKING. DX: SEVERE MU...   \n",
       "1        611          0  80 YR MALE FELL IN BATHROOM/HE HIT RIGHT RIBS ...   \n",
       "2       1328          0  4 YR MALE HAD METAL LARGE WAGON WHEEL FALL & H...   \n",
       "3       1205          0  CONTUSION EAR - STRUCK IN RIGHT EAR WITH BASKE...   \n",
       "4       5031          0     SPRAIN THUMB - INJURED THUMB WHEN SNOWBOARDING   \n",
       "\n",
       "                            Narrative_2 Stratum  PSU   Weight  \n",
       "0               /RIGHT BUTTOCKS & BACK.       S   71  68.1086  \n",
       "1  DX: FRACTURED RIGHT RIBS-UPPER TRUNK       S   71  68.1086  \n",
       "2          DX: CONTUSIN ON HEAD/NO LOC.       S   71  68.1086  \n",
       "3                                   NaN       S    7  68.1086  \n",
       "4                                   NaN       S    7  68.1086  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNeiss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Neiss with column code dictionary from Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_codes_fname = neiss_pathname + '/column_codes.xlsx'\n",
    "column_dictionary = getColumnCodeDictionary(column_codes_fname)\n",
    "Neiss.setColumnCodeDictionary(column_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Code to take the Neiss dictionaries for column codes and write them out to the column_codes.xlsx file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "neiss = Neiss(dfNeiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352927, 19)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNeiss.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a categorical dataframe (with a subset of the overall data 3000 random rows)\n",
    "\n",
    "The dataframe is built of columns that are only categorical in nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Body_Part</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>Location</th>\n",
       "      <th>Fire_Involvement</th>\n",
       "      <th>Product_1</th>\n",
       "      <th>Product_2</th>\n",
       "      <th>PSU</th>\n",
       "      <th>Stratum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>125620</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3299</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58602</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1205</td>\n",
       "      <td>1807</td>\n",
       "      <td>14</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340873</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4074</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163289</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4076</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>381726</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4076</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sex  Race  Body_Part  Diagnosis  Disposition  Location  \\\n",
       "125620    1     0         79         64            1         0   \n",
       "58602     1     0         75         62            1         9   \n",
       "340873    1     0         75         52            1         0   \n",
       "163289    2     3         32         55            1         1   \n",
       "381726    1     2         36         53            1         1   \n",
       "\n",
       "        Fire_Involvement  Product_1  Product_2  PSU Stratum  \n",
       "125620                 0       3299          0   89       L  \n",
       "58602                  0       1205       1807   14       M  \n",
       "340873                 0       4074          0   41       V  \n",
       "163289                 0       4076          0    8       C  \n",
       "381726                 0       4076          0   57       V  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the  matrix (contingency table)\n",
    "\n",
    "categories = ['Sex', 'Race', 'Body_Part', 'Diagnosis', 'Disposition', 'Location',\n",
    "    'Fire_Involvement', 'Product_1', 'Product_2', 'PSU', 'Stratum' ]\n",
    "\n",
    "dfCategorical = dfNeiss.copy()\n",
    "dfCategorical = dfCategorical.xs(categories, axis=1)\n",
    "dfCategorical.dropna(inplace=True)\n",
    "dfCategorical['Race'] = [int(x) for x in dfCategorical['Race']]\n",
    "dfCategorical = dfCategorical.sample(3000)\n",
    "dfCategorical.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the code ID translator for the dfCategorical dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  translator\n",
      "Function Category                                                           \n",
      "codeToId Body_Part         [{0: 1, 30: 2, 31: 3, 32: 4, 33: 5, 34: 6, 35:...\n",
      "         Diagnosis         [{41: 1, 42: 2, 46: 3, 48: 4, 49: 5, 50: 6, 51...\n",
      "         Disposition            [{1: 1, 2: 2, 4: 3, 5: 4, 6: 5, 8: 6, 9: 7}]\n",
      "         Fire_Involvement                   [{0: 1, 1: 2, 2: 3, 3: 4, 4: 5}]\n",
      "         Location               [{0: 1, 1: 2, 2: 3, 4: 4, 5: 5, 8: 6, 9: 7}]\n",
      "         PSU               [{1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8:...\n",
      "         Product_1         [{115: 1, 134: 2, 214: 3, 215: 4, 218: 5, 227:...\n",
      "         Product_2         [{0: 1, 140: 2, 266: 3, 273: 4, 276: 5, 279: 6...\n",
      "         Race                   [{0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7}]\n",
      "         Sex                                                  [{1: 1, 2: 2}]\n",
      "         Stratum                  [{'C': 1, 'L': 2, 'M': 3, 'S': 4, 'V': 5}]\n",
      "idToCode Body_Part         [{1: 0, 2: 30, 3: 31, 4: 32, 5: 33, 6: 34, 7: ...\n",
      "         Diagnosis         [{1: 41, 2: 42, 3: 46, 4: 48, 5: 49, 6: 50, 7:...\n",
      "         Disposition            [{1: 1, 2: 2, 3: 4, 4: 5, 5: 6, 6: 8, 7: 9}]\n",
      "         Fire_Involvement                   [{1: 0, 2: 1, 3: 2, 4: 3, 5: 4}]\n",
      "         Location               [{1: 0, 2: 1, 3: 2, 4: 4, 5: 5, 6: 8, 7: 9}]\n",
      "         PSU               [{1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8:...\n",
      "         Product_1         [{1: 115, 2: 134, 3: 214, 4: 215, 5: 218, 6: 2...\n",
      "         Product_2         [{1: 0, 2: 140, 3: 266, 4: 273, 5: 276, 6: 279...\n",
      "         Race                   [{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6}]\n",
      "         Sex                                                  [{1: 1, 2: 2}]\n",
      "         Stratum                  [{1: 'C', 2: 'L', 3: 'M', 4: 'S', 5: 'V'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<code_id_translator.CodeIdTranslatorDataFrame at 0x1518435f8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeIdTranslator = CodeIdTranslatorDataFrame(dfCategorical, categories)\n",
    "codeIdTranslator.transformColumns()\n",
    "codeIdTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentState = codeIdTranslator.getState()\n",
    "\n",
    "codeIdTranslator.setState('id')\n",
    "dfCorrelationsId = codeIdTranslator.getDataFrame().copy()\n",
    "\n",
    "codeIdTranslator.setState('code')\n",
    "dfCorrelationsCode = codeIdTranslator.getDataFrame().copy()\n",
    "\n",
    "codeIdTranslator.setState(currentState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show time based graphs of male/female injuries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.TimeBasedGraphs:\n",
    "    stat_name = 'Sex'\n",
    "    date_name = 'Treatment_Date'\n",
    "\n",
    "    TimeBasedGraphs(dfNeiss, Neiss.getColumnDictionary(stat_name), date_name, stat_name).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions/Classes used for the python correlations and pearson chi squared correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHighCorrelations(df, dfCategoricalCorrMatrix, minValue):\n",
    "    '''\n",
    "    For each column in the dataframe determine which rows equal or exceed the minimum value\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame):    The original dataframe\n",
    "        dfCategoricalCorrMatrix  (list of (row_name, col_name) tuples): The categorical matrix\n",
    "        minValue (int):  The value the row/column cell must equal or exceed\n",
    "\n",
    "    Returns:\n",
    "      A list of tuples containing (row, column) where the value equalled or exceeded the minimum value\n",
    "    '''\n",
    "    high_correlations = []\n",
    "    for yIndex, y in enumerate(dfCategoricalCorrMatrix.index):\n",
    "        for xIndex, x in enumerate(dfCategoricalCorrMatrix.columns):\n",
    "            #if xIndex >= yIndex:\n",
    "            #    break\n",
    "\n",
    "            if (x != y) and (dfCategoricalCorrMatrix[y][x] > minValue):\n",
    "                Y = y\n",
    "                X = x\n",
    "                if len(df[X].unique()) > len(df[Y].unique()):\n",
    "                    # Keep the smallest item on the X axis\n",
    "                    Y, X = X, Y\n",
    "\n",
    "                if (Y, X) not in high_correlations:\n",
    "                    high_correlations.insert(-1, (Y, X))\n",
    "    high_correlations.sort()\n",
    "    return high_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserSelectableSwarmScatterPlots():\n",
    "    def __init__(self, high_correlations, code_id_translator):\n",
    "        self.button = widgets.Button(description=\"Click Me!\")\n",
    "        self.output = widgets.Output()\n",
    "        self.high_correlations = high_correlations\n",
    "        self.code_id_translator = code_id_translator\n",
    "\n",
    "    def show(self):\n",
    "        button = widgets.Button(description=\"Click Me!\")\n",
    "        output = widgets.Output()\n",
    "\n",
    "        #print(self.high_correlations.values)\n",
    "        select = self.high_correlations[0]\n",
    "        #print(select)\n",
    "        lCorrelations = ['{}, {}'.format(y, x) for y, x in self.high_correlations]\n",
    "        correlationDropDownSel = widgets.Dropdown(\n",
    "            options=lCorrelations,\n",
    "            value=lCorrelations[0],\n",
    "            description='correlations',\n",
    "            disabled=False,\n",
    "        )\n",
    "\n",
    "        typeDropDownSel = widgets.Dropdown(\n",
    "            options=['swarm', 'scatter'],\n",
    "            value='swarm',\n",
    "            description='plot_type',\n",
    "            disabled=False,\n",
    "        )\n",
    "\n",
    "        wHBox = widgets.HBox([correlationDropDownSel, typeDropDownSel])\n",
    "        wVBox = widgets.VBox([wHBox, button, output])\n",
    "\n",
    "        display(wVBox)\n",
    "\n",
    "        def on_button_clicked(b):\n",
    "            with output:\n",
    "                sel = correlationDropDownSel.value\n",
    "                (xSel, ySel) = [x.strip() for x in sel.split(',')]\n",
    "                print('-{}-, -{}-'.format(xSel, ySel))\n",
    "\n",
    "                correlations(self.code_id_translator, xSel, ySel, typeDropDownSel.value)\n",
    "\n",
    "                #sns.pairplot(dfSel, hue=xSel)\n",
    "\n",
    "        button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalMatrixHeatMap:\n",
    "    def __init__(self, title, dfCategoricalMatrix):\n",
    "        self.title = title\n",
    "        self.dfCategoricalMatrix = dfCategoricalMatrix\n",
    "\n",
    "    def show(self):\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "        g = sns.heatmap(self.dfCategoricalMatrix, annot=True, linewidths=0.4, ax=ax)\n",
    "        g.set_title(self.title)\n",
    "\n",
    "        # Fix the top and bottom margins of the heatmap\n",
    "        bottom_y, top_y = plt.ylim() \n",
    "        bottom_y += 0.5 \n",
    "        top_y -= 0.5 \n",
    "        plt.ylim(bottom_y, top_y)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.PythonCorr:\n",
    "    methods = {\n",
    "        'pearson' : 'Pearson R Correlation (parametric)',  # not good for categorical data\n",
    "            # For pearson:\n",
    "            # both variables should be normally distributed\n",
    "            # There should be no significant outliers\n",
    "            # Each variable should be continuous\n",
    "            # The two variables have a linear relationship\n",
    "            # The observations are paired observations.\n",
    "            # Should support homoscedascity.  Homoscedascity simply refers to ‘equal variances’.\n",
    "        'kendall' : 'Kendall Tau-b rank correlation (non-parametric)',\n",
    "            # The variables are measured on an ordinal or continuous scale.\n",
    "            # Desirable if your data appears to follow a monotonic relationship.\n",
    "        'spearman' : 'Spearman rank correlation (non-parametric)'\n",
    "            # Does not assume that both datasets are normally distributed\n",
    "        }\n",
    "\n",
    "    dfCategoricalMatrices = {}\n",
    "    for key in methods.keys():\n",
    "        dfCategoricalMatrices[key] = dfCategorical.corr(method = key)\n",
    "        heatMap = CategoricalMatrixHeatMap(methods[key], dfCategoricalMatrices[key])\n",
    "        heatMap.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if True == Includes.PythonCorr:\n",
    "#    for key in dfCategoricalMatrices.keys():\n",
    "#        print('{}:\\n{}'.format(key, dfCategoricalMatrices))\n",
    "#        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.PythonCorr:\n",
    "    highCorrelationsPythonCorr = getHighCorrelations(\n",
    "        dfCategorical,\n",
    "        dfCategoricalMatrices['spearman'],\n",
    "        0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if True == Includes.PythonCorr:\n",
    "#    for n in highCorrelationsPythonCorr:\n",
    "#        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.PythonCorr:\n",
    "    plots = UserSelectableSwarmScatterPlots(highCorrelationsPythonCorr, codeIdTranslator)\n",
    "    plots.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PearsonChiSquared\n",
    "\n",
    "https://machinelearningmastery.com/chi-squared-test-for-machine-learning/\n",
    "\n",
    "'The Pearson’s chi-squared statistical hypothesis is an example of a test for independence between categorical variables.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.PearsonChiSquared:\n",
    "    pearsonChiSquared = PearsonChiSquared(dfCategorical)\n",
    "    dfPersonChiSquaredCategoricalCorrMatrix = pearsonChiSquared.getCorrMatrixDataframe(categories)\n",
    "    #print(dfCategoricalCorrMatrix.head())\n",
    "\n",
    "    heatMap = CategoricalMatrixHeatMap('Pearson Chi Squared', dfPersonChiSquaredCategoricalCorrMatrix)\n",
    "    heatMap.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.PearsonChiSquared:\n",
    "    highCorrelationsPearsonChiSquared = getHighCorrelations(\n",
    "        dfCategorical,\n",
    "        dfPersonChiSquaredCategoricalCorrMatrix,\n",
    "        0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if True == Includes.PearsonChiSquared:\n",
    "#    for n in highCorrelationsPearsonChiSquared:\n",
    "#        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.PearsonChiSquared:\n",
    "    plots = UserSelectableSwarmScatterPlots(highCorrelationsPearsonChiSquared, codeIdTranslator)\n",
    "    plots.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression (using chi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html\n",
    "\n",
    "- f_classif:  ANOVA F-value between label/feature for classification tasks.\n",
    "\n",
    "- mutual_info_classif: Mutual information for a discrete target.\n",
    "\n",
    "- chi2:  Chi-squared stats of non-negative features for classification tasks.\n",
    "\n",
    "- f_regression:  F-value between label/feature for regression tasks.\n",
    "\n",
    "- mutual_info_regression:  Mutual information for a continuous target.\n",
    "    \n",
    "- SelectPercentile:  Select features based on percentile of the highest scores.\n",
    "\n",
    "- SelectFpr:  Select features based on a false positive rate test.\n",
    "\n",
    "- SelectFdr:  Select features based on an estimated false discovery rate.\n",
    "\n",
    "- SelectFwe:  Select features based on family-wise error rate.\n",
    "\n",
    "- GenericUnivariateSelect:  Univariate feature selector with configurable mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, chi2, f_regression, mutual_info_regression\n",
    "from sklearn.feature_selection import SelectPercentile, SelectFpr, SelectFdr, SelectFwe, GenericUnivariateSelect\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.metrics import mean_squared_error, r2_score, scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.LinearRegressionChi2:\n",
    "    class LinearRegressionChi2():\n",
    "        def __init__(self, outputFeature, categories, dfCorrelationsId):\n",
    "            self.outputFeature = outputFeature\n",
    "            self.categories = categories.copy()\n",
    "            self.dfKBest = dfCorrelationsId.copy()\n",
    "        \n",
    "            self.categories.remove(self.outputFeature)\n",
    "\n",
    "            self.y = self.dfKBest[self.outputFeature]\n",
    "            self.selector = SelectKBest(chi2, k=3)\n",
    "            self.selector.fit(self.dfKBest[self.categories].values, self.y)\n",
    "            self.selector.get_support()\n",
    "\n",
    "            self.selected_columns = np.asarray(self.categories)[self.selector.get_support()]\n",
    "            self.X = self.dfKBest[self.selected_columns]\n",
    "    \n",
    "            \n",
    "        def plot_scatter(X,Y,R=None):\n",
    "            plt.scatter(X, Y, s=32, marker='o', facecolors='none', edgecolors='k')\n",
    "            if R is not None:\n",
    "                plt.scatter(X, R, color='red', linewidth=0.5)\n",
    "            plt.show()  \n",
    "\n",
    "        def showShape(self):\n",
    "            print('X.shape={}'.format(self.X.shape))\n",
    "            print()\n",
    "\n",
    "        def showSelectedColumns(self):\n",
    "            print('selected_columns={}'.format(self.selected_columns))\n",
    "            print()\n",
    "\n",
    "        def showSelectorScores(self):\n",
    "            print('selector.scores_={}'.format(self.selector.scores_))\n",
    "            print()\n",
    "\n",
    "        def showSelectorSupport(self):\n",
    "            print('selector.get_support()={}'.format(self.selector.get_support()))\n",
    "            print()\n",
    "\n",
    "        def showPlots(self):\n",
    "            for category in self.X:\n",
    "                print('x=', category)\n",
    "                x = np.asarray(self.dfKBest[category]).reshape(-1, 1)\n",
    "                regressor = LinearRegression(normalize=True).fit(x, self.y)\n",
    "                y_pred    = regressor.predict(x)\n",
    "                LinearRegressionChi2.plot_scatter(x, self.y, y_pred)\n",
    "                print(\"R-squared score: {:.4f}\".format(r2_score(self.y, y_pred)))\n",
    "                print()\n",
    "                print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.LinearRegressionChi2:\n",
    "    linearRegressionChi2 = LinearRegressionChi2('Diagnosis', categories, dfCorrelationsId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.LinearRegressionChi2:\n",
    "    linearRegressionChi2.showShape()\n",
    "    linearRegressionChi2.showSelectedColumns()\n",
    "    linearRegressionChi2.showSelectorScores()\n",
    "    linearRegressionChi2.showSelectorSupport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.LinearRegressionChi2:\n",
    "    linearRegressionChi2.showPlots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes (GaussianNB)\n",
    "\n",
    "\n",
    "Can perform online updates to model parameters via partial_fit method. \n",
    "\n",
    "For details on algorithm used to update feature means and variance online, \n",
    "\n",
    "see Stanford CS tech report STAN-CS-79-773 by Chan, Golub, and LeVeque:\n",
    "\n",
    "\n",
    "http://i.stanford.edu/pub/cstr/reports/cs/tr/79/773/CS-TR-79-773.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.GaussianNB:\n",
    "    def buildLe(df, verbose=False):\n",
    "        dfCorrelationsCodeLe = df.copy()\n",
    "        leGaussianNB = {}\n",
    "\n",
    "        for col in dfCorrelationsCodeLe.columns:\n",
    "            leGaussianNB[col] = preprocessing.LabelEncoder()\n",
    "            leGaussianNB[col].fit(dfCorrelationsCodeLe[col].unique())\n",
    "\n",
    "            if True == verbose:\n",
    "                print('{0:12s} => {1}'.format(col, leGaussianNB[col].classes_))\n",
    "\n",
    "            dfCorrelationsCodeLe[col] = leGaussianNB[col].transform(dfCorrelationsCodeLe[col])\n",
    "\n",
    "        if True == verbose:\n",
    "            print(dfCorrelationsCodeLe)\n",
    "        return leGaussianNB\n",
    "\n",
    "    leGaussianNB = buildLe(dfCorrelationsCode.copy(), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.GaussianNB:\n",
    "    class WorkingGaussianNB():\n",
    "        def __init__(self, outputFeature, categories, dfCorrelationsId):\n",
    "            self.outputFeature = outputFeature\n",
    "            self.categories = categories.copy()\n",
    "            self.df = dfCorrelationsId.copy()\n",
    "    \n",
    "            self.categories.remove(outputFeature)\n",
    "\n",
    "            for category in self.categories:\n",
    "                print(category, end=' - ')\n",
    "\n",
    "                inputFeature = [category]\n",
    "\n",
    "                # Train classifier\n",
    "                gnb = GaussianNB()\n",
    "                gnb.fit(\n",
    "                    self.df[inputFeature].values,\n",
    "                    self.df[outputFeature]\n",
    "                )\n",
    "\n",
    "                y_pred = gnb.predict(self.df[inputFeature])\n",
    "\n",
    "                # Print results\n",
    "                print(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\"\n",
    "                      .format(\n",
    "                          self.df.shape[0],\n",
    "                          (self.df[self.outputFeature] != y_pred).sum(),\n",
    "                          100*(1-(self.df[self.outputFeature] != y_pred).sum()/self.df.shape[0])\n",
    "                ), end=' ')\n",
    "\n",
    "                self.dfPredicted = pd.DataFrame()\n",
    "                try:\n",
    "                    self.dfPredicted = pd.DataFrame(\n",
    "                        {'predicted': leGaussianNB[self.outputFeature].inverse_transform(y_pred),\n",
    "                         'actual':    self.df[self.outputFeature]})\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                self.confusion_matrix = metrics.confusion_matrix(y_pred, self.df[self.outputFeature])\n",
    "                print('complete')\n",
    "\n",
    "        def showPredicted(self):\n",
    "            print('dfPredicted:\\n{}'.format(self.dfPredicted))\n",
    "\n",
    "        def showConfusionMatrix(self):\n",
    "            print('confusion_matrix:\\n{}'.format(self.confusion_matrix))\n",
    "\n",
    "        def compute(self, show_predicted_versus_actual=True, show_confusion_matrices=True):\n",
    "            # Drop categories with low scores\n",
    "            categories = self.categories.copy()\n",
    "            categories.remove('Sex')\n",
    "            categories.remove('Disposition')\n",
    "            categories.remove('Location')\n",
    "            categories.remove('Product_2')\n",
    "            categories.remove('Stratum')\n",
    "\n",
    "            df = self.df.copy()\n",
    "            df.drop(['Sex', 'Disposition', 'Location', 'Product_2', 'Stratum'], axis=1, inplace=True)\n",
    "\n",
    "            predictedOutputs = {}\n",
    "            for category in categories:\n",
    "                print('{}:  '.format(category), end=' ')\n",
    "\n",
    "                inputFeature = [category]\n",
    "\n",
    "                # Train classifier\n",
    "                gnb = GaussianNB()\n",
    "                gnb.fit(\n",
    "                    df[inputFeature].values,\n",
    "                    df[self.outputFeature]\n",
    "                )\n",
    "\n",
    "                y_pred = gnb.predict(self.df[inputFeature])\n",
    "                #print(y_pred)\n",
    "\n",
    "                # Print results\n",
    "                print(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\"\n",
    "                      .format(\n",
    "                          df.shape[0],\n",
    "                          (df[self.outputFeature] != y_pred).sum(),\n",
    "                          100*(1-(df[self.outputFeature] != y_pred).sum()/df.shape[0])\n",
    "                ))\n",
    "                \n",
    "                dfPredicted = pd.DataFrame(\n",
    "                    {'predicted': leGaussianNB[self.outputFeature].inverse_transform(y_pred),\n",
    "                     'actual':    df[self.outputFeature]})\n",
    "\n",
    "                if True == show_predicted_versus_actual:\n",
    "                    print(dfPredicted)\n",
    "\n",
    "                predictedOutputs[category] = y_pred\n",
    "\n",
    "                if True == show_confusion_matrices:\n",
    "                    print('\\nConfusion matrices')\n",
    "                    for catecory in predictedOutputs:\n",
    "                            print(\"----------------------------\")\n",
    "                            print('{}:'.format(category))\n",
    "                            print()\n",
    "\n",
    "                            # df[self.outputFeature] has 29 unique values.  That is why there are 29 columns\n",
    "                            print(metrics.confusion_matrix(predictedOutputs[catecory], df[self.outputFeature]))\n",
    "                            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex - Number of mislabeled points out of a total 3000 points : 2998, performance 00.07% complete\n",
      "Race - Number of mislabeled points out of a total 3000 points : 2757, performance 08.10% complete\n",
      "Body_Part - Number of mislabeled points out of a total 3000 points : 2468, performance 17.73% complete\n",
      "Disposition - Number of mislabeled points out of a total 3000 points : 2932, performance 02.27% complete\n",
      "Location - Number of mislabeled points out of a total 3000 points : 2826, performance 05.80% complete\n",
      "Fire_Involvement - Number of mislabeled points out of a total 3000 points : 2510, performance 16.33% complete\n",
      "Product_1 - Number of mislabeled points out of a total 3000 points : 2376, performance 20.80% complete\n",
      "Product_2 - Number of mislabeled points out of a total 3000 points : 2928, performance 02.40% complete\n",
      "PSU - Number of mislabeled points out of a total 3000 points : 2402, performance 19.93% complete\n",
      "Stratum - Number of mislabeled points out of a total 3000 points : 2835, performance 05.50% complete\n"
     ]
    }
   ],
   "source": [
    "if True == Includes.GaussianNB:\n",
    "    gaussianNB = WorkingGaussianNB('Diagnosis', categories, dfCorrelationsId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if True == Includes.GaussianNB:\n",
    "#    gaussianNB.showPredicted()\n",
    "#    gaussianNB.showConfusionMatrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Race:   Number of mislabeled points out of a total 3000 points : 2757, performance 08.10%\n",
      "Body_Part:   Number of mislabeled points out of a total 3000 points : 2468, performance 17.73%\n",
      "Fire_Involvement:   Number of mislabeled points out of a total 3000 points : 2510, performance 16.33%\n",
      "Product_1:   Number of mislabeled points out of a total 3000 points : 2376, performance 20.80%\n",
      "PSU:   Number of mislabeled points out of a total 3000 points : 2402, performance 19.93%\n"
     ]
    }
   ],
   "source": [
    "if True == Includes.GaussianNB:\n",
    "    gaussianNB.compute(show_predicted_versus_actual=False, show_confusion_matrices=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceValueWithStringInColumn(column_name, replace_value, with_string):\n",
    "    dfDecisionTree[column_name] = [\n",
    "            with_string if str(x) == '{}'.format(replace_value) else x \n",
    "            for x in dfDecisionTree[column_name]]  # Replace zeros in col='disposition' with 'Unknown'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkForNumericValueInColumn(columnName):\n",
    "    for index, value in enumerate(dfDecisionTree[columnName]):\n",
    "        if type(value) == int:\n",
    "            if 'Treatment_Date' in dfDecisionTree.columns:\n",
    "                print('{}: Found int={} at {} - {}'.format(\n",
    "                    columnName, value, index, dfDecisionTree['Treatment_Date'].iloc[index]))\n",
    "            else:\n",
    "                print('{}: Found int={} at {}'.format(columnName, value, index))\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOnHotEncodedDataframe(df):\n",
    "    '''\n",
    "    Take columns that are objects and turn them into multiple one-hot columns.\n",
    "\n",
    "    Args:\n",
    "        df    (pd.DataFrame):  The dataframe to convert to a one-hot dataframe\n",
    "\n",
    "    Returns:\n",
    "        dfOneHot (pd.DataFrame):  A dataframe with the original objects replaced with one-hot versions.\n",
    "\n",
    "\n",
    "    Example dataframe:\n",
    "\n",
    "        Cost(dollars)  Item\n",
    "        2              'Baseball'\n",
    "        5              'Baseball Glove'\n",
    "        7              'Helmet'\n",
    "\n",
    "    Will become a dataframe similar to:\n",
    "\n",
    "        Cost(dollars)  ('Item', 'Baseball')    ('Item', 'Baseball Glove')  ('Item', 'Helmet)\n",
    "        2              1                       0                           0\n",
    "        5              0                       1                           0\n",
    "        7              0                       0                           1\n",
    "\n",
    "    By making a tuple for the column header it is easy to determine the variable that the one-hot\n",
    "    column represents.\n",
    "    '''\n",
    "    dfOneHot = df.copy()\n",
    "\n",
    "    updateFreq = 100\n",
    "    print('Dots are printed every {} translations'.format(updateFreq))\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object:\n",
    "            print('Transforming {:20s}'.format(col), end='\\t')\n",
    "\n",
    "            unique = pd.unique(df[col].sort_values(ascending=True))\n",
    "            nUnique = len(unique)\n",
    "            print('nUnique={}'.format(nUnique), end='\\t')\n",
    "\n",
    "            updateIndex = updateFreq\n",
    "            updateNext = updateFreq\n",
    "\n",
    "            for index, value in enumerate(unique):\n",
    "                if index == updateIndex:\n",
    "                    updateIndex += updateFreq\n",
    "                    updateNext += updateFreq\n",
    "                    print('.', end='')\n",
    "                    \n",
    "                dfOneHot[(col, value)] = (dfOneHot[col] == value).astype(int)\n",
    "            dfOneHot.drop(columns=[col], inplace=True)\n",
    "            print('\\tcomplete')\n",
    "    return dfOneHot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfNeissDecisionTree = neiss.getDataFrame().copy()\n",
    "\n",
    "# Remove columns containing NaN or columns where the number of unique items is greater than \n",
    "toBeDropped = []\n",
    "for col in dfNeissDecisionTree.columns:\n",
    "    if dfNeissDecisionTree[col].isnull().values.any():\n",
    "        toBeDropped.append(col)\n",
    "\n",
    "# Also remove the case number and the narrative\n",
    "toBeDropped.extend(['CPSC_Case_Number', 'Narrative_1'])\n",
    "\n",
    "# The following dates (1999 ... 2013) contain codes that do not match the column_codes table.\n",
    "dfNeissDecisionTree = dfNeissDecisionTree[\n",
    "    ~dfNeissDecisionTree['Treatment_Date'].dt.year.isin(list(range(1999, 2013)))]\n",
    "\n",
    "#toBeDropped.extend(['Treatment_Date'])\n",
    "dfNeissDecisionTree.drop(toBeDropped, axis=1, inplace=True)\n",
    "\n",
    "# Remove values from dates (2014 ... 2018) that do not have column codes for them\n",
    "dfNeissDecisionTree = dfNeissDecisionTree[~dfNeissDecisionTree['Product_1'].isin([1841, 1903])]\n",
    "dfNeissDecisionTree = dfNeissDecisionTree[~dfNeissDecisionTree['Product_2'].isin([1841, 1903])]\n",
    "\n",
    "dfNeissDecisionTree['mDate'] = mdates.date2num(dfNeissDecisionTree['Treatment_Date']) \n",
    "dfNeissDecisionTree.drop(['Treatment_Date'], axis=1, inplace=True)\n",
    "\n",
    "#dfDecisionTree = Neiss.translateCodes(dfNeissDecisionTree[0 : len(dfNeissDecisionTree) // 4])  # Use 1/4 the data\n",
    "#dfDecisionTree = Neiss.translateCodes(dfNeissDecisionTree[0 : len(dfNeissDecisionTree) // 2])  # Use 1/2 the data\n",
    "dfDecisionTree = Neiss.translateCodes(dfNeissDecisionTree)\n",
    "\n",
    "\n",
    "replaceValueWithStringInColumn('Product_1', 0, 'Zero') # Keep the zero.\n",
    "replaceValueWithStringInColumn('Product_2', 0, 'Zero') # Especially for Product_2.\n",
    "replaceValueWithStringInColumn('Fire_Involvement', 4, 'InvalidCode')\n",
    "\n",
    "\n",
    "for col in dfDecisionTree.columns:\n",
    "    print('{:20s}\\tnunique={}\\tnum_nulls={}\\ttype={}'.format(\n",
    "        col,\n",
    "        dfDecisionTree[col].nunique(),\n",
    "        dfDecisionTree[col].isnull().sum(),\n",
    "        dfDecisionTree[col].dtype))\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkForNumericValueInColumn('Disposition')\n",
    "checkForNumericValueInColumn('Fire_Involvement')\n",
    "checkForNumericValueInColumn('Product_1')\n",
    "checkForNumericValueInColumn('Product_2')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOneHot = createOnHotEncodedDataframe(dfDecisionTree)\n",
    "\n",
    "yLabels = []\n",
    "for col in dfOneHot.columns:\n",
    "    if col[0] == 'Diagnosis':\n",
    "        yLabels.append(col)\n",
    "\n",
    "xLabels = [value for value in dfOneHot.columns if value not in yLabels]\n",
    "\n",
    "x = dfOneHot[xLabels]\n",
    "y = dfOneHot[yLabels]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfDecisionTree = DecisionTreeClassifier() # gini is the default criterion\n",
    "#clfDecisionTree = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "clfDecisionTreeFit = clfDecisionTree.fit(x, y)\n",
    "print(clfDecisionTreeFit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***** \n",
    "- Full data model accuracy\n",
    "- ***** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clfDecisionTreeFit.predict(x)\n",
    "y_pred\n",
    "\n",
    "# Model accuracy\n",
    "metrics.accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code generates the following error for some reason:\n",
    "#    Error: neiss_2013_2018: syntax error in line 743 near ','\n",
    "\n",
    "#dot_data=export_graphviz(clfDecisionTreeFit, out_file=None, \n",
    "#                     feature_names=xLabels,  # inputs\n",
    "#                     class_names=yLabels, # outputs \n",
    "#                     filled=True, rounded=True,   \n",
    "#                     special_characters=True)  \n",
    "#graph = graphviz.Source(dot_data) \n",
    "#graph.render(\"neiss_2013_2018\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!open neiss_2013_2018.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***** \n",
    "- Now with 70% training set, 30% testing set\n",
    "- ***** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bu_id = 7286\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=bu_id)\n",
    "\n",
    "clfGini = DecisionTreeClassifier()\n",
    "clfGiniFit = clfGini.fit(X_train, y_train)\n",
    "print(clfGiniFit)\n",
    "\n",
    "y_pred = clfGiniFit.predict(X_test)\n",
    "# print(y_pred)\n",
    "\n",
    "# Model accuracy\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
