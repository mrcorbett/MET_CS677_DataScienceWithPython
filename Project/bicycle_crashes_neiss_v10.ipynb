{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bicycle Crash analysis NEISS data 1999 to 2018\n",
    "## National Electronic Injury Surveillance System\n",
    "\n",
    "https://github.com/mrcorbett/MET_CS677_DataScienceWithPython/tree/master\n",
    "\n",
    "\n",
    "\"CPSCâ€™s National Electronic Injury Surveillance System (NEISS) is a national probability sample of hospitals in the U.S. and its territories. Patient information is collected from each NEISS hospital for every emergency visit involving an injury associated with consumer products.\"\n",
    "\n",
    "https://catalog.data.gov/dataset/cpscs-national-electronic-injury-surveillance-system-neiss\n",
    "https://www.cpsc.gov/cgibin/NEISSQuery/home.aspx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import calendar\n",
    "from code_id_translator import *\n",
    "from datetime import datetime\n",
    "import graphviz\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, fixed\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.pyplot as plt\n",
    "from neiss_backend import *\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, chi2, f_regression, mutual_info_regression\n",
    "from sklearn.feature_selection import SelectPercentile, SelectFpr, SelectFdr, SelectFwe, GenericUnivariateSelect\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz, plot_tree\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from time_based_graphs import *\n",
    "import xlrd\n",
    "\n",
    "#from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Includes():\n",
    "    TimeBasedGraphs = True\n",
    "    PearsonChiSquared = True\n",
    "    PythonCorr = True\n",
    "    LinearRegressionChi2 = True\n",
    "    LogisticRegression = True\n",
    "    GaussianNB = True\n",
    "    DecisionTree = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Selection of geographic areas called primary sampling units (PSU) that are defined within sampling strata. \n",
    "\n",
    "https://www.cdc.gov/nchs/nhis/singleton_psu.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the pickled neissYYYY.xlsx file\n",
    "\n",
    "convert_neiss_original_data_to_pckl.ipynb is used to create the pickled file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- If the neiss_data.pckl file exists read it as the data file.\n",
    "- Otherwise, raise an exception.\n",
    "\n",
    "See convert_neiss_original_data_to_pckl.ipynb for the creation of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/mcorbett/Boston University/MET_CS677_DataScienceWithPython/Project/data/NEISS/neiss_data.pckl  ... done!\n"
     ]
    }
   ],
   "source": [
    "neiss_pathname = os.getcwd() + '/data/NEISS'\n",
    "\n",
    "pckl_fname = neiss_pathname + '/neiss_data.pckl'\n",
    "if os.path.exists(pckl_fname):\n",
    "    print(\"Reading {}  ... \".format(pckl_fname), end=\"\")\n",
    "    dfNeiss = pickle.load( open( pckl_fname, \"rb\" ) )\n",
    "    print(\"done!\")\n",
    "else:\n",
    "    raise Exception(\n",
    "        'ERROR:  {} does not exist\\n  Use \"convert_neiss_original_data_to_pckl.ipynb\" to create the pckl file'.format(\n",
    "            pckl_fname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352927, 19)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNeiss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPSC_Case_Number</th>\n",
       "      <th>Treatment_Date</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Other_Race</th>\n",
       "      <th>Body_Part</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Other_Diagnosis</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>Location</th>\n",
       "      <th>Fire_Involvement</th>\n",
       "      <th>Product_1</th>\n",
       "      <th>Product_2</th>\n",
       "      <th>Narrative_1</th>\n",
       "      <th>Narrative_2</th>\n",
       "      <th>Stratum</th>\n",
       "      <th>PSU</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100001</td>\n",
       "      <td>1999-12-24</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3299</td>\n",
       "      <td>0</td>\n",
       "      <td>41 YR FEMALE FELL WHILE WALKING. DX: SEVERE MU...</td>\n",
       "      <td>/RIGHT BUTTOCKS &amp; BACK.</td>\n",
       "      <td>S</td>\n",
       "      <td>71</td>\n",
       "      <td>68.1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>100002</td>\n",
       "      <td>1999-12-27</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>611</td>\n",
       "      <td>0</td>\n",
       "      <td>80 YR MALE FELL IN BATHROOM/HE HIT RIGHT RIBS ...</td>\n",
       "      <td>DX: FRACTURED RIGHT RIBS-UPPER TRUNK</td>\n",
       "      <td>S</td>\n",
       "      <td>71</td>\n",
       "      <td>68.1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100003</td>\n",
       "      <td>1999-12-27</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1328</td>\n",
       "      <td>0</td>\n",
       "      <td>4 YR MALE HAD METAL LARGE WAGON WHEEL FALL &amp; H...</td>\n",
       "      <td>DX: CONTUSIN ON HEAD/NO LOC.</td>\n",
       "      <td>S</td>\n",
       "      <td>71</td>\n",
       "      <td>68.1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>100005</td>\n",
       "      <td>1999-12-28</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1205</td>\n",
       "      <td>0</td>\n",
       "      <td>CONTUSION EAR - STRUCK IN RIGHT EAR WITH BASKE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7</td>\n",
       "      <td>68.1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>100009</td>\n",
       "      <td>1999-12-28</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5031</td>\n",
       "      <td>0</td>\n",
       "      <td>SPRAIN THUMB - INJURED THUMB WHEN SNOWBOARDING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7</td>\n",
       "      <td>68.1086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CPSC_Case_Number Treatment_Date  Age  Sex  Race Other_Race  Body_Part  \\\n",
       "0            100001     1999-12-24   41    2   1.0          0         31   \n",
       "1            100002     1999-12-27   80    1   2.0          0         31   \n",
       "2            100003     1999-12-27    4    1   1.0          0         75   \n",
       "3            100005     1999-12-28   18    1   0.0        NaN         94   \n",
       "4            100009     1999-12-28   19    2   0.0        NaN         92   \n",
       "\n",
       "   Diagnosis Other_Diagnosis  Disposition  Location  Fire_Involvement  \\\n",
       "0         71             NaN            1         0                 0   \n",
       "1         57             NaN            1         0                 0   \n",
       "2         53             NaN            1         0                 0   \n",
       "3         53             NaN            1         0                 0   \n",
       "4         64             NaN            1         0                 0   \n",
       "\n",
       "   Product_1  Product_2                                        Narrative_1  \\\n",
       "0       3299          0  41 YR FEMALE FELL WHILE WALKING. DX: SEVERE MU...   \n",
       "1        611          0  80 YR MALE FELL IN BATHROOM/HE HIT RIGHT RIBS ...   \n",
       "2       1328          0  4 YR MALE HAD METAL LARGE WAGON WHEEL FALL & H...   \n",
       "3       1205          0  CONTUSION EAR - STRUCK IN RIGHT EAR WITH BASKE...   \n",
       "4       5031          0     SPRAIN THUMB - INJURED THUMB WHEN SNOWBOARDING   \n",
       "\n",
       "                            Narrative_2 Stratum  PSU   Weight  \n",
       "0               /RIGHT BUTTOCKS & BACK.       S   71  68.1086  \n",
       "1  DX: FRACTURED RIGHT RIBS-UPPER TRUNK       S   71  68.1086  \n",
       "2          DX: CONTUSIN ON HEAD/NO LOC.       S   71  68.1086  \n",
       "3                                   NaN       S    7  68.1086  \n",
       "4                                   NaN       S    7  68.1086  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNeiss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Neiss with column code dictionary from Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_codes_fname = neiss_pathname + '/column_codes.xlsx'\n",
    "column_dictionary = getColumnCodeDictionary(column_codes_fname)\n",
    "Neiss.setColumnCodeDictionary(column_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Code to take the Neiss dictionaries for column codes and write them out to the column_codes.xlsx file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "neiss = Neiss(dfNeiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352927, 19)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNeiss.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a categorical dataframe (with a subset of the overall data 3000 random rows)\n",
    "\n",
    "The dataframe is built of columns that are only categorical in nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFramePruner():\n",
    "    def __init__(self, dict_prune=dict(), max_output_rows=None, keep_end=True):\n",
    "        '''\n",
    "        Prune a dataframe based on a dictionary and the maximum number of output rows\n",
    "        \n",
    "        Args:\n",
    "          dict_prune  (dict):  Of the form {col_name : max_output_categories, ...}\n",
    "          max_output_rows (int):  If none, all rows are kept.  Otherwise, the dataframe is clipped to this number of rows maximum.\n",
    "          keep_end (bool):  True, max_output_rows is relative to the end of the dataframe.  False, from beginning.\n",
    "        '''\n",
    "        self.dict_prune = dict_prune\n",
    "        self.max_output_rows = max_output_rows\n",
    "        self.keep_end = keep_end\n",
    "\n",
    "    def _limitColumnCategoriesTo(df, column_name, num_categories):\n",
    "        '''\n",
    "         Get the top 'num_categories' most frequent names in self.df[column_name]\n",
    "\n",
    "         Args:\n",
    "             column_name (str):  The name of the column to limit the categories on\n",
    "             num_categories (int):  The maximum number of unique values to retain in 'column_name'\n",
    "        '''\n",
    "        selected = df[column_name].value_counts()[:num_categories].index.tolist()\n",
    "        return df[df[column_name].isin(selected)]\n",
    "\n",
    "    def prune(self, df):\n",
    "        for column_name in self.dict_prune.keys():\n",
    "            df = DataFramePruner._limitColumnCategoriesTo(df, column_name, self.dict_prune[column_name])\n",
    "\n",
    "        if None != self.max_output_rows:\n",
    "            if True == self.keep_end:\n",
    "                df = df[-self.max_output_rows : ]\n",
    "            else:\n",
    "                df = df[0 : self.max_output_rows]\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeissSubset():\n",
    "    def __init__(self, df, categories, dataframe_pruner=None):\n",
    "        self.df = df.copy()\n",
    "        self.categories = categories.copy()\n",
    "\n",
    "        self.df = self.df.xs(self.categories, axis=1)\n",
    "        self.df.dropna(inplace=True)\n",
    "        self.df['Race'] = [int(x) for x in self.df['Race']]\n",
    "        \n",
    "        if None != dataframe_pruner:\n",
    "            self.df = dataframe_pruner.prune(self.df)\n",
    "\n",
    "        self.updateCodeIdVariables()\n",
    "\n",
    "    def updateCodeIdVariables(self):\n",
    "        # Get the code ID translator for the dataframe\n",
    "        self.codeIdTranslator = CodeIdTranslatorDataFrame(self.df, self.categories)\n",
    "        self.codeIdTranslator.transformColumns()\n",
    "\n",
    "        # Get the code ID translators for the dataframe\n",
    "        currentState = self.codeIdTranslator.getState()\n",
    "\n",
    "        self.codeIdTranslator.setState('id')\n",
    "        self.dfIdToCode = self.codeIdTranslator.getDataFrame().copy()\n",
    "\n",
    "        self.codeIdTranslator.setState('code')\n",
    "        self.dfCodeToId = self.codeIdTranslator.getDataFrame().copy()\n",
    "\n",
    "        self.codeIdTranslator.setState(currentState)\n",
    "\n",
    "    def limitColumnCategoriesTo(self, column_name, num_categories):\n",
    "        '''\n",
    "         Get the top 'num_categories' most frequent names in self.df[column_name]\n",
    "         \n",
    "         Args:\n",
    "             column_name (str):  The name of the column to limit the categories on\n",
    "             num_categories (int):  The maximum number of unique values to retain in 'column_name'\n",
    "        '''\n",
    "        selected = self.df[column_name].value_counts()[:num_categories].index.tolist()\n",
    "        self.df = self.df[self.df[column_name].isin(selected)]\n",
    "        #self.updateCodeIdVariables()\n",
    "\n",
    "    def limitMaxRowsTo(self, num_rows):\n",
    "        self.df = self.df.sample(num_rows)\n",
    "        #self.updateCodeIdVariables()\n",
    "\n",
    "    def getDataFrame(self):\n",
    "        return self.df\n",
    "\n",
    "    def getCategories(self):\n",
    "        return self.categories\n",
    "    \n",
    "    def getCodeIdTranslator(self):\n",
    "        return self.codeIdTranslator\n",
    "    \n",
    "    def getIdToCodeDataframe(self):\n",
    "        return self.dfIdToCode\n",
    "    \n",
    "    def getCodeToIdDataframe(self):\n",
    "        return self.dfCodeToId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_choice = 'Diagnosis'\n",
    "\n",
    "pruner = DataFramePruner(dict_prune={output_choice : 10}, max_output_rows=100000, keep_end=True)\n",
    "\n",
    "neissSubset = NeissSubset(dfNeiss,\n",
    "    categories=['Sex', 'Race', 'Body_Part', 'Diagnosis', 'Disposition', 'Location',\n",
    "    'Fire_Involvement', 'Product_1', 'Product_2', 'PSU', 'Stratum' ],\n",
    "    dataframe_pruner=pruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 11)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neissSubset.getDataFrame().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Body_Part</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>Location</th>\n",
       "      <th>Fire_Involvement</th>\n",
       "      <th>Product_1</th>\n",
       "      <th>Product_2</th>\n",
       "      <th>PSU</th>\n",
       "      <th>Stratum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>253053</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>639</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253054</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>580</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253055</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>520</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253056</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>288</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253057</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>445</td>\n",
       "      <td>94</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sex  Race  Body_Part  Diagnosis  Disposition  Location  \\\n",
       "253053    2     2         10          1            1         9   \n",
       "253054    3     2          5          6            1         2   \n",
       "253055    2     3         16          6            1         1   \n",
       "253056    3     2         11          5            1         5   \n",
       "253057    3     2          1          5            1         5   \n",
       "\n",
       "        Fire_Involvement  Product_1  Product_2  PSU  Stratum  \n",
       "253053                 1        639          1    4        2  \n",
       "253054                 1        580          1    4        2  \n",
       "253055                 1        520          1    4        2  \n",
       "253056                 1        288          1    4        2  \n",
       "253057                 1        445         94    4        2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neissSubset.getDataFrame().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the IdToCode and CodeToId translators for the neissSubset dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Body_Part</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>Location</th>\n",
       "      <th>Fire_Involvement</th>\n",
       "      <th>Product_1</th>\n",
       "      <th>Product_2</th>\n",
       "      <th>PSU</th>\n",
       "      <th>Stratum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>253053</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>639</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253054</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>580</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253055</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>520</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253056</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>288</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253057</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>445</td>\n",
       "      <td>94</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sex  Race  Body_Part  Diagnosis  Disposition  Location  \\\n",
       "253053    2     2         10          1            1         9   \n",
       "253054    3     2          5          6            1         2   \n",
       "253055    2     3         16          6            1         1   \n",
       "253056    3     2         11          5            1         5   \n",
       "253057    3     2          1          5            1         5   \n",
       "\n",
       "        Fire_Involvement  Product_1  Product_2  PSU  Stratum  \n",
       "253053                 1        639          1    4        2  \n",
       "253054                 1        580          1    4        2  \n",
       "253055                 1        520          1    4        2  \n",
       "253056                 1        288          1    4        2  \n",
       "253057                 1        445         94    4        2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neissSubset.getIdToCodeDataframe().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Body_Part</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Disposition</th>\n",
       "      <th>Location</th>\n",
       "      <th>Fire_Involvement</th>\n",
       "      <th>Product_1</th>\n",
       "      <th>Product_2</th>\n",
       "      <th>PSU</th>\n",
       "      <th>Stratum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>253053</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5033</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253054</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4004</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253055</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1894</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253056</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1141</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253057</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1645</td>\n",
       "      <td>611</td>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sex  Race  Body_Part  Diagnosis  Disposition  Location  \\\n",
       "253053    1     1         75         52            1         9   \n",
       "253054    2     1         34         59            1         1   \n",
       "253055    1     2         82         59            1         0   \n",
       "253056    2     1         76         57            1         5   \n",
       "253057    2     1         30         57            1         5   \n",
       "\n",
       "        Fire_Involvement  Product_1  Product_2  PSU Stratum  \n",
       "253053                 0       5033          0    5       L  \n",
       "253054                 0       4004          0    5       L  \n",
       "253055                 0       1894          0    5       L  \n",
       "253056                 0       1141          0    5       L  \n",
       "253057                 0       1645        611    5       L  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "neissSubset.getCodeToIdDataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show time based graphs of male/female injuries - whole dataframe used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.TimeBasedGraphs:\n",
    "    stat_name = 'Sex'\n",
    "    date_name = 'Treatment_Date'\n",
    "\n",
    "    TimeBasedGraphs(dfNeiss, Neiss.getColumnDictionary(stat_name), date_name, stat_name).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions/Classes used for the python correlations and pearson chi squared correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHighCorrelations(df, dfCategoricalCorrMatrix, minValue):\n",
    "    '''\n",
    "    For each column in the dataframe determine which rows equal or exceed the minimum value\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame):    The original dataframe\n",
    "        dfCategoricalCorrMatrix  (list of (row_name, col_name) tuples): The categorical matrix\n",
    "        minValue (int):  The value the row/column cell must equal or exceed\n",
    "\n",
    "    Returns:\n",
    "      A list of tuples containing (row, column) where the value equalled or exceeded the minimum value\n",
    "    '''\n",
    "    high_correlations = []\n",
    "    for yIndex, y in enumerate(dfCategoricalCorrMatrix.index):\n",
    "        for xIndex, x in enumerate(dfCategoricalCorrMatrix.columns):\n",
    "            #if xIndex >= yIndex:\n",
    "            #    break\n",
    "\n",
    "            if (x != y) and (dfCategoricalCorrMatrix[y][x] > minValue):\n",
    "                Y = y\n",
    "                X = x\n",
    "                if len(df[X].unique()) > len(df[Y].unique()):\n",
    "                    # Keep the smallest item on the X axis\n",
    "                    Y, X = X, Y\n",
    "\n",
    "                if (Y, X) not in high_correlations:\n",
    "                    high_correlations.insert(-1, (Y, X))\n",
    "    high_correlations.sort()\n",
    "    return high_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserSelectableSwarmScatterPlots():\n",
    "    def __init__(self, high_correlations, code_id_translator):\n",
    "        self.button = widgets.Button(description=\"Click Me!\")\n",
    "        self.output = widgets.Output()\n",
    "        self.high_correlations = high_correlations\n",
    "        self.code_id_translator = code_id_translator\n",
    "\n",
    "    def show(self):\n",
    "        button = widgets.Button(description=\"Click Me!\")\n",
    "        output = widgets.Output()\n",
    "\n",
    "        #print(self.high_correlations.values)\n",
    "        select = self.high_correlations[0]\n",
    "        #print(select)\n",
    "        lCorrelations = ['{}, {}'.format(y, x) for y, x in self.high_correlations]\n",
    "        correlationDropDownSel = widgets.Dropdown(\n",
    "            options=lCorrelations,\n",
    "            value=lCorrelations[0],\n",
    "            description='correlations',\n",
    "            disabled=False,\n",
    "        )\n",
    "\n",
    "        typeDropDownSel = widgets.Dropdown(\n",
    "            options=['swarm', 'scatter'],\n",
    "            value='swarm',\n",
    "            description='plot_type',\n",
    "            disabled=False,\n",
    "        )\n",
    "\n",
    "        wHBox = widgets.HBox([correlationDropDownSel, typeDropDownSel])\n",
    "        wVBox = widgets.VBox([wHBox, button, output])\n",
    "\n",
    "        display(wVBox)\n",
    "\n",
    "        def on_button_clicked(b):\n",
    "            with output:\n",
    "                sel = correlationDropDownSel.value\n",
    "                (xSel, ySel) = [x.strip() for x in sel.split(',')]\n",
    "                print('-{}-, -{}-'.format(xSel, ySel))\n",
    "\n",
    "                correlations(self.code_id_translator, xSel, ySel, typeDropDownSel.value)\n",
    "\n",
    "                #sns.pairplot(dfSel, hue=xSel)\n",
    "\n",
    "        button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalMatrixHeatMap:\n",
    "    def __init__(self, title, dfCategoricalMatrix):\n",
    "        self.title = title\n",
    "        self.dfCategoricalMatrix = dfCategoricalMatrix\n",
    "\n",
    "    def show(self):\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "        g = sns.heatmap(self.dfCategoricalMatrix, annot=True, linewidths=0.4, ax=ax)\n",
    "        g.set_title(self.title)\n",
    "\n",
    "        # Fix the top and bottom margins of the heatmap\n",
    "        bottom_y, top_y = plt.ylim() \n",
    "        bottom_y += 0.5 \n",
    "        top_y -= 0.5 \n",
    "        plt.ylim(bottom_y, top_y)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Corr - dataframe subset used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.PythonCorr:\n",
    "    methods = {\n",
    "        'pearson' : 'Pearson R Correlation (parametric)',  # not good for categorical data\n",
    "            # For pearson:\n",
    "            # both variables should be normally distributed\n",
    "            # There should be no significant outliers\n",
    "            # Each variable should be continuous\n",
    "            # The two variables have a linear relationship\n",
    "            # The observations are paired observations.\n",
    "            # Should support homoscedascity.  Homoscedascity simply refers to â€˜equal variancesâ€™.\n",
    "        'kendall' : 'Kendall Tau-b rank correlation (non-parametric)',\n",
    "            # The variables are measured on an ordinal or continuous scale.\n",
    "            # Desirable if your data appears to follow a monotonic relationship.\n",
    "        'spearman' : 'Spearman rank correlation (non-parametric)'\n",
    "            # Does not assume that both datasets are normally distributed\n",
    "        }\n",
    "\n",
    "    dfCategoricalMatrices = {}\n",
    "    for key in methods.keys():\n",
    "        dfCategoricalMatrices[key] = neissSubset.getDataFrame().corr(method = key)\n",
    "        heatMap = CategoricalMatrixHeatMap(methods[key], dfCategoricalMatrices[key])\n",
    "        heatMap.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if True == Includes.PythonCorr:\n",
    "#    for key in dfCategoricalMatrices.keys():\n",
    "#        print('{}:\\n{}'.format(key, dfCategoricalMatrices))\n",
    "#        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.PythonCorr:\n",
    "    highCorrelationsPythonCorr = getHighCorrelations(\n",
    "        neissSubset.getDataFrame(),\n",
    "        dfCategoricalMatrices['spearman'],\n",
    "        0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if True == Includes.PythonCorr:\n",
    "#    for n in highCorrelationsPythonCorr:\n",
    "#        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.PythonCorr:\n",
    "    plots = UserSelectableSwarmScatterPlots(highCorrelationsPythonCorr, neissSubset.getCodeIdTranslator())\n",
    "    plots.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PearsonChiSquared - dataframe subset used\n",
    "\n",
    "https://machinelearningmastery.com/chi-squared-test-for-machine-learning/\n",
    "\n",
    "'The Pearsonâ€™s chi-squared statistical hypothesis is an example of a test for independence between categorical variables.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.PearsonChiSquared:\n",
    "    pearsonChiSquared = PearsonChiSquared(neissSubset.getDataFrame())\n",
    "    dfPersonChiSquaredCategoricalCorrMatrix = pearsonChiSquared.getCorrMatrixDataframe(neissSubset.getCategories())\n",
    "    #print(dfCategoricalCorrMatrix.head())\n",
    "\n",
    "    heatMap = CategoricalMatrixHeatMap('Pearson Chi Squared', dfPersonChiSquaredCategoricalCorrMatrix)\n",
    "    heatMap.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.PearsonChiSquared:\n",
    "    highCorrelationsPearsonChiSquared = getHighCorrelations(\n",
    "        neissSubset.getDataFrame(),\n",
    "        dfPersonChiSquaredCategoricalCorrMatrix,\n",
    "        0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if True == Includes.PearsonChiSquared:\n",
    "#    for n in highCorrelationsPearsonChiSquared:\n",
    "#        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.PearsonChiSquared:\n",
    "    plots = UserSelectableSwarmScatterPlots(highCorrelationsPearsonChiSquared, neissSubset.getCodeIdTranslator())\n",
    "    plots.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression (using chi2) - dataframe subset used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html\n",
    "\n",
    "- f_classif:  ANOVA F-value between label/feature for classification tasks.\n",
    "\n",
    "- mutual_info_classif: Mutual information for a discrete target.\n",
    "\n",
    "- chi2:  Chi-squared stats of non-negative features for classification tasks.\n",
    "\n",
    "- f_regression:  F-value between label/feature for regression tasks.\n",
    "\n",
    "- mutual_info_regression:  Mutual information for a continuous target.\n",
    "    \n",
    "- SelectPercentile:  Select features based on percentile of the highest scores.\n",
    "\n",
    "- SelectFpr:  Select features based on a false positive rate test.\n",
    "\n",
    "- SelectFdr:  Select features based on an estimated false discovery rate.\n",
    "\n",
    "- SelectFwe:  Select features based on family-wise error rate.\n",
    "\n",
    "- GenericUnivariateSelect:  Univariate feature selector with configurable mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.LinearRegressionChi2:\n",
    "    class WorkingLinearRegressionChi2():\n",
    "        def __init__(self, outputFeature, categories, dfIdToCode):\n",
    "            self.outputFeature = outputFeature\n",
    "            self.categories = categories.copy()\n",
    "            self.dfKBest = dfIdToCode.copy()\n",
    "        \n",
    "            self.categories.remove(self.outputFeature)\n",
    "\n",
    "            self.y = self.dfKBest[self.outputFeature]\n",
    "            self.selector = SelectKBest(chi2, k=3)\n",
    "            self.selector.fit(self.dfKBest[self.categories].values, self.y)\n",
    "            self.selector.get_support()\n",
    "\n",
    "            self.selected_columns = np.asarray(self.categories)[self.selector.get_support()]\n",
    "            self.X = self.dfKBest[self.selected_columns]\n",
    "    \n",
    "            \n",
    "        def plot_scatter(X,Y,R=None):\n",
    "            plt.scatter(X, Y, s=32, marker='o', facecolors='none', edgecolors='k')\n",
    "            if R is not None:\n",
    "                plt.scatter(X, R, color='red', linewidth=0.5)\n",
    "            plt.show()  \n",
    "\n",
    "        def showShape(self):\n",
    "            print('X.shape={}'.format(self.X.shape))\n",
    "            print()\n",
    "\n",
    "        def showSelectedColumns(self):\n",
    "            print('selected_columns={}'.format(self.selected_columns))\n",
    "            print()\n",
    "\n",
    "        def showSelectorScores(self):\n",
    "            print('selector.scores_={}'.format(self.selector.scores_))\n",
    "            print()\n",
    "\n",
    "        def showSelectorSupport(self):\n",
    "            print('selector.get_support()={}'.format(self.selector.get_support()))\n",
    "            print()\n",
    "\n",
    "        def showPlots(self):\n",
    "            for category in self.X:\n",
    "                print('x=', category)\n",
    "                x = np.asarray(self.dfKBest[category]).reshape(-1, 1)\n",
    "                regressor = LinearRegression(normalize=True).fit(x, self.y)\n",
    "                y_pred    = regressor.predict(x)\n",
    "                WorkingLinearRegressionChi2.plot_scatter(x, self.y, y_pred)\n",
    "                print(\"R-squared score: {:.4f}\".format(r2_score(self.y, y_pred)))\n",
    "                print()\n",
    "                print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.LinearRegressionChi2:\n",
    "    linearRegressionChi2 = WorkingLinearRegressionChi2(\n",
    "        output_choice, neissSubset.getCategories(), neissSubset.getIdToCodeDataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.LinearRegressionChi2:\n",
    "    linearRegressionChi2.showShape()\n",
    "    linearRegressionChi2.showSelectedColumns()\n",
    "    linearRegressionChi2.showSelectorScores()\n",
    "    linearRegressionChi2.showSelectorSupport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.LinearRegressionChi2:\n",
    "    linearRegressionChi2.showPlots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.LogisticRegression:\n",
    "    class WorkingLogisticRegression():\n",
    "        '''\n",
    "        Based loosly on:  https://acadgild.com/blog/logistic-regression-multiclass-classification\n",
    "        '''\n",
    "        def __init__(self, outputFeature, categories, dfIdToCode, codeIdTranslator):\n",
    "            self.outputFeature = outputFeature\n",
    "            self.categories = categories.copy()\n",
    "            self.df = dfIdToCode.copy()\n",
    "            self.codeIdTranslator = codeIdTranslator\n",
    "        \n",
    "            self.categories.remove(self.outputFeature)\n",
    "    \n",
    "            self.inputs = self.df[self.categories]\n",
    "            self.output = self.df[self.outputFeature]\n",
    "            \n",
    "            self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(\n",
    "                self.inputs, self.output, test_size=1/7.0, random_state=122)\n",
    "\n",
    "            # Standardize the data\n",
    "            scaler = StandardScaler()\n",
    "            \n",
    "            # Fit on training set only.\n",
    "            scaler.fit(self.x_train)\n",
    "\n",
    "            # Apply transform to both the training set and the test set.\n",
    "            self.x_train = scaler.transform(self.x_train)\n",
    "            self.x_test = scaler.transform(self.x_test)\n",
    "\n",
    "            # Fit the model\n",
    "            # For multiclass problems, only â€˜newton-cgâ€™, â€˜sagâ€™, â€˜sagaâ€™ and â€˜lbfgsâ€™ handle multinomial loss.\n",
    "            #self.model = LogisticRegression(solver = 'lbfgs', multi_class='multinomial', max_iter=1000)\n",
    "            self.model = LogisticRegression(solver = 'newton-cg', multi_class='multinomial', max_iter=1000)\n",
    "            self.model.fit(self.x_train, self.y_train)\n",
    "\n",
    "            # Validate the fitting\n",
    "            # use the model to make predictions with the test data\n",
    "            self.y_pred = self.model.predict(self.x_test)\n",
    "\n",
    "            self.probs = self.model.predict_proba(self.x_test)\n",
    "            test_score = self.model.score(self.x_test, self.y_test)\n",
    "            print('test_score =', test_score)\n",
    "\n",
    "            # how did our model perform?\n",
    "            self.count_misclassified = (self.y_test != self.y_pred).sum()\n",
    "            self.accuracy = metrics.accuracy_score(self.y_test, self.y_pred)\n",
    "\n",
    "            self.confusion_matrix = metrics.confusion_matrix(self.y_test, self.y_pred)\n",
    "\n",
    "            # Create predicted versus actual dataframe\n",
    "            target_names = self.output.unique()\n",
    "\n",
    "            target_dict = column_dictionary[self.outputFeature]\n",
    "\n",
    "            dfTest = pd.DataFrame(self.y_test, columns=[self.outputFeature])\n",
    "            self.codeIdTranslator._transform(dfTest, 'idToCode', self.outputFeature)\n",
    "            y_test = [target_dict[x] for x in dfTest[self.outputFeature]]\n",
    "            #print('y_test={}'.format( np.sort(np.unique(y_test)) ))\n",
    "            \n",
    "            dfPred = pd.DataFrame(self.y_pred, columns=[self.outputFeature])\n",
    "            self.codeIdTranslator._transform(dfPred, 'idToCode', self.outputFeature)\n",
    "            y_pred = [target_dict[x] for x in dfPred[self.outputFeature]]\n",
    "            #print('y_pred={}'.format( np.sort(np.unique(y_pred)) ))\n",
    "\n",
    "            dfTargetNames = pd.DataFrame(target_names, columns=[self.outputFeature])\n",
    "            self.codeIdTranslator._transform(dfTargetNames, 'idToCode', self.outputFeature)\n",
    "            target_names =  [target_dict[x] for x in dfTargetNames[self.outputFeature]]\n",
    "            #print('target_names={}'.format( np.sort(np.unique(target_names)) ))\n",
    "\n",
    "            self.dfPredictedVersusActual = pd.DataFrame(self.probs, columns=target_names).round(4)\n",
    "            self.dfPredictedVersusActual.insert(0, 'target_class',    y_test)\n",
    "            self.dfPredictedVersusActual.insert(1, 'predicted_class', y_pred)\n",
    "            \n",
    "        def showAccuracy(self):\n",
    "            print('Accuracy: {:.2f}'.format(self.accuracy))\n",
    "\n",
    "        def showMissclassifiedSamples(self):\n",
    "            print('Misclassified samples: {} out of {}'.format(self.count_misclassified, len(self.y_test)))\n",
    "\n",
    "        def showConfusionMatrix(self):\n",
    "            print('Confusion Matrix:\\n{}'.format(self.confusion_matrix))\n",
    "\n",
    "        def getPredictedVersusActualDataframe(self):\n",
    "            #state = self.codeIdTranslator.getState()\n",
    "            return self.dfPredictedVersusActual\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.LogisticRegression:\n",
    "    logisticRegression = WorkingLogisticRegression(\n",
    "        output_choice,\n",
    "        neissSubset.getCategories(),\n",
    "        neissSubset.getIdToCodeDataframe(),    # neissSubset.getIdToCodeDataframe()[0:1500]\n",
    "        neissSubset.getCodeIdTranslator())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.LogisticRegression:\n",
    "    logisticRegression.showAccuracy()\n",
    "    logisticRegression.showMissclassifiedSamples()\n",
    "    #logisticRegression.showConfusionMatrix()\n",
    "    dfPredictedVersusActual = logisticRegression.getPredictedVersusActualDataframe()\n",
    "    display(dfPredictedVersusActual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes (GaussianNB) - dataframe subset used\n",
    "\n",
    "\n",
    "Can perform online updates to model parameters via partial_fit method. \n",
    "\n",
    "For details on algorithm used to update feature means and variance online, \n",
    "\n",
    "see Stanford CS tech report STAN-CS-79-773 by Chan, Golub, and LeVeque:\n",
    "\n",
    "\n",
    "http://i.stanford.edu/pub/cstr/reports/cs/tr/79/773/CS-TR-79-773.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.GaussianNB:\n",
    "    class WorkingGaussianNB():\n",
    "        def __init__(self, outputFeature, categories, dfIdToCode, verbose=False):\n",
    "            self.outputFeature = outputFeature\n",
    "            self.categories = categories.copy()\n",
    "            self.df = dfIdToCode.copy()\n",
    "    \n",
    "            self.categories.remove(outputFeature)\n",
    "\n",
    "            # Build the Label encoder\n",
    "            self.le = {}\n",
    "            for col in self.df.columns:\n",
    "                self.le[col] = preprocessing.LabelEncoder()\n",
    "                self.le[col].fit(self.df[col].unique())\n",
    "\n",
    "                if True == verbose:\n",
    "                    print('{0:12s} => {1}'.format(col, self.le[col].classes_))\n",
    "\n",
    "\n",
    "            # Train classifier\n",
    "            for category in self.categories:\n",
    "                print(category, end=' - ')\n",
    "                inputFeature = [category]\n",
    "\n",
    "                gnb = GaussianNB()\n",
    "                gnb.fit(\n",
    "                    self.df[inputFeature].values,\n",
    "                    self.df[outputFeature]\n",
    "                )\n",
    "\n",
    "                y_pred = gnb.predict(self.df[inputFeature])\n",
    "\n",
    "                # Print results\n",
    "                print(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\"\n",
    "                      .format(\n",
    "                          self.df.shape[0],\n",
    "                          (self.df[self.outputFeature] != y_pred).sum(),\n",
    "                          100*(1-(self.df[self.outputFeature] != y_pred).sum()/self.df.shape[0])\n",
    "                ), end=' ')\n",
    "\n",
    "                self.dfPredicted = pd.DataFrame()\n",
    "                try:\n",
    "                    self.dfPredicted = pd.DataFrame(\n",
    "                        {'predicted': self.le[self.outputFeature].inverse_transform(y_pred),\n",
    "                         'actual':    self.df[self.outputFeature]})\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                self.confusion_matrix = metrics.confusion_matrix(y_pred, self.df[self.outputFeature])\n",
    "                print('complete')\n",
    "\n",
    "        def showPredicted(self):\n",
    "            print('dfPredicted:\\n{}'.format(self.dfPredicted))\n",
    "\n",
    "        def showConfusionMatrix(self):\n",
    "            print('confusion_matrix:\\n{}'.format(self.confusion_matrix))\n",
    "\n",
    "        def compute(self, show_predicted_versus_actual=True, show_confusion_matrices=True):\n",
    "            # Drop categories with low scores\n",
    "            categories = self.categories.copy()\n",
    "            categories.remove('Sex')\n",
    "            categories.remove('Disposition')\n",
    "            categories.remove('Location')\n",
    "            categories.remove('Product_2')\n",
    "            categories.remove('Stratum')\n",
    "\n",
    "            df = self.df.copy()\n",
    "            df.drop(['Sex', 'Disposition', 'Location', 'Product_2', 'Stratum'], axis=1, inplace=True)\n",
    "\n",
    "            predictedOutputs = {}\n",
    "            for category in categories:\n",
    "                print('{}:  '.format(category), end=' ')\n",
    "\n",
    "                inputFeature = [category]\n",
    "\n",
    "                # Train classifier\n",
    "                gnb = GaussianNB()\n",
    "                gnb.fit(\n",
    "                    df[inputFeature].values,\n",
    "                    df[self.outputFeature]\n",
    "                )\n",
    "\n",
    "                y_pred = gnb.predict(self.df[inputFeature])\n",
    "                #print(y_pred)\n",
    "\n",
    "                # Print results\n",
    "                print(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\"\n",
    "                      .format(\n",
    "                          df.shape[0],\n",
    "                          (df[self.outputFeature] != y_pred).sum(),\n",
    "                          100*(1-(df[self.outputFeature] != y_pred).sum()/df.shape[0])\n",
    "                ))\n",
    "                \n",
    "                dfPredicted = pd.DataFrame(\n",
    "                    {'predicted': self.le[self.outputFeature].inverse_transform(y_pred),\n",
    "                     'actual':    df[self.outputFeature]})\n",
    "\n",
    "                if True == show_predicted_versus_actual:\n",
    "                    print(dfPredicted)\n",
    "\n",
    "                predictedOutputs[category] = y_pred\n",
    "\n",
    "                if True == show_confusion_matrices:\n",
    "                    print('\\nConfusion matrices')\n",
    "                    for catecory in predictedOutputs:\n",
    "                            print(\"----------------------------\")\n",
    "                            print('{}:'.format(category))\n",
    "                            print()\n",
    "\n",
    "                            # df[self.outputFeature] has 29 unique values.  That is why there are 29 columns\n",
    "                            print(metrics.confusion_matrix(predictedOutputs[catecory], df[self.outputFeature]))\n",
    "                            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.GaussianNB:\n",
    "    gaussianNB = WorkingGaussianNB(\n",
    "        output_choice, neissSubset.getCategories(), neissSubset.getIdToCodeDataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if True == Includes.GaussianNB:\n",
    "#    gaussianNB.showPredicted()\n",
    "#    gaussianNB.showConfusionMatrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.GaussianNB:\n",
    "    gaussianNB.compute(show_predicted_versus_actual=False, show_confusion_matrices=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree - dataframe subset used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.DecisionTree:\n",
    "    class WorkingDecisionTree():\n",
    "        #def __init__(self, df, output_choice, max_output_categories=None, max_output_rows=None):\n",
    "        def __init__(self, df, output_choice, dataframe_pruner=None):\n",
    "            self.df = df.copy()\n",
    "            self.output_choice = output_choice\n",
    "\n",
    "            if None != dataframe_pruner:\n",
    "                self.df = dataframe_pruner.prune(self.df)\n",
    "\n",
    "            #if None != max_output_categories:\n",
    "            #    self.limitColumnCategoriesTo(self.output_choice, max_output_categories)\n",
    "\n",
    "            #if None != max_output_rows:\n",
    "            #    self.df = self.df[-max_output_rows : ]\n",
    "\n",
    "            # Remove columns containing NaN or columns where the number of unique items is greater than \n",
    "            toBeDropped = []\n",
    "            for col in self.df.columns:\n",
    "                if self.df[col].isnull().values.any():\n",
    "                    toBeDropped.append(col)\n",
    "\n",
    "\n",
    "            # Also remove the case number and the narrative\n",
    "            toBeDropped.extend(['CPSC_Case_Number', 'Narrative_1'])\n",
    "\n",
    "            # The following dates (1999 ... 2013) contain codes that do not match the column_codes table.\n",
    "            self.df = self.df[~self.df['Treatment_Date'].dt.year.isin(list(range(1999, 2013)))]\n",
    "\n",
    "            self.df.drop(toBeDropped, axis=1, inplace=True)\n",
    "\n",
    "            # Remove values from dates (2014 ... 2018) that do not have column codes for them\n",
    "            self.df = self.df[~self.df['Product_1'].isin([1841, 1903])]\n",
    "            self.df = self.df[~self.df['Product_2'].isin([1841, 1903])]\n",
    "\n",
    "            self.df['mDate'] = mdates.date2num(self.df['Treatment_Date']) \n",
    "            self.df.drop(['Treatment_Date'], axis=1, inplace=True)\n",
    "\n",
    "            self.dfDecisionTree = Neiss.translateCodes(self.df)\n",
    "\n",
    "            self.replaceValueWithStringInColumn('Product_1', 0, 'Zero') # Keep the zero.\n",
    "            self.replaceValueWithStringInColumn('Product_2', 0, 'Zero') # Especially for Product_2.\n",
    "            self.replaceValueWithStringInColumn('Fire_Involvement', 4, 'InvalidCode')\n",
    "\n",
    "\n",
    "            #self.checkForNumericValueInColumn('Disposition')\n",
    "            self.checkForNumericValueInColumn('Fire_Involvement')\n",
    "            self.checkForNumericValueInColumn('Product_1')\n",
    "            self.checkForNumericValueInColumn('Product_2')\n",
    "\n",
    "            self.dfOneHot = WorkingDecisionTree.createOnHotEncodedDataframe(self.dfDecisionTree)\n",
    "            #print('dfOneHot.shape =', self.dfOneHot.shape)\n",
    "            #print('dfOneHot.columns =', self.dfOneHot.columns)\n",
    "\n",
    "            self.y_labels = []\n",
    "            for col_value in self.dfOneHot.columns:\n",
    "                if col_value[0] == self.output_choice:\n",
    "                    self.y_labels.append(col_value)\n",
    "\n",
    "            self.x_labels = [value for value in self.dfOneHot.columns if value not in self.y_labels]\n",
    "\n",
    "            self.x = self.dfOneHot[self.x_labels]\n",
    "            self.y = self.dfOneHot[self.y_labels]\n",
    "            #print('y_labels =', self.y_labels)\n",
    "            #print('x.shape =', self.x.shape)\n",
    "            #print('y.shape =', self.y.shape)\n",
    "\n",
    "            #print()\n",
    "            #for col in self.dfDecisionTree.columns:\n",
    "            #    print('{:20s}\\tnunique={}\\tnum_nulls={}\\ttype={}'.format(\n",
    "            #        col,\n",
    "            #        self.dfDecisionTree[col].nunique(),\n",
    "            #        self.dfDecisionTree[col].isnull().sum(),\n",
    "            #        self.dfDecisionTree[col].dtype))\n",
    "\n",
    "            print('Done')\n",
    "\n",
    "            \n",
    "        def fullTestTrainAccuracy(self, criterion='gini', graph_viz=False, out_file=None, render_name=None):\n",
    "             # gini is the default criterion\n",
    "\n",
    "            #print('x.shape =', self.x.shape)\n",
    "            #print('y.shape =', self.y.shape)\n",
    "\n",
    "            clfDecisionTree = DecisionTreeClassifier(criterion=criterion)\n",
    "            clfDecisionTreeFit = clfDecisionTree.fit(self.x, self.y)\n",
    "            y_pred = clfDecisionTreeFit.predict(self.x)\n",
    "\n",
    "            # Model accuracy\n",
    "            accuracy = metrics.accuracy_score(self.y, y_pred)\n",
    "            print('Accuracy =', accuracy)\n",
    "\n",
    "            # This code generates the following error for some reason:\n",
    "            #    Error: neiss_2013_2018: syntax error in line 743 near ','\n",
    "            if True == graph_viz:\n",
    "                dot_data = export_graphviz(\n",
    "                    clfDecisionTreeFit, out_file=out_file, \n",
    "                    feature_names = self.x_labels,    # inputs\n",
    "                    class_names   = self.y_labels,    # outputs \n",
    "                    filled=True, rounded=True,   \n",
    "                    special_characters=True)  \n",
    "\n",
    "                graph = graphviz.Source(dot_data) \n",
    "                if None != render_name:\n",
    "                    graph.render(render_name)\n",
    "\n",
    "        def splitTestTrainAccuracy(self, \n",
    "            criterion='gini', random_state=1, test_size=0.3,\n",
    "            graph_viz=False, out_file=None, render_name=None):\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                self.x, self.y, test_size=0.3, random_state=bu_id)\n",
    "\n",
    "            clfDecisionTree = DecisionTreeClassifier(criterion=criterion)\n",
    "            clfDecisionTreeFit = clfDecisionTree.fit(X_train, y_train)\n",
    "            print(clfDecisionTreeFit)\n",
    "\n",
    "            y_pred = clfDecisionTreeFit.predict(X_test)\n",
    "            # print(y_pred)\n",
    "\n",
    "            # Model accuracy\n",
    "            accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "            print('Accuracy =', accuracy)\n",
    "\n",
    "            # This code generates the following error for some reason:\n",
    "            #    Error: neiss_2013_2018: syntax error in line 743 near ','\n",
    "            if True == graph_viz:\n",
    "                dot_data = export_graphviz(\n",
    "                    clfDecisionTreeFit, out_file=out_file, \n",
    "                    feature_names = self.x_labels,    # inputs\n",
    "                    class_names   = self.y_labels,    # outputs \n",
    "                    filled=True, rounded=True,   \n",
    "                    special_characters=True)  \n",
    "\n",
    "                graph = graphviz.Source(dot_data) \n",
    "                if None != render_name:\n",
    "                    graph.render(render_name)\n",
    "            \n",
    "        def limitColumnCategoriesTo(self, column_name, num_categories):\n",
    "            '''\n",
    "             Get the top 'num_categories' most frequent names in self.df[column_name]\n",
    "\n",
    "             Args:\n",
    "                 column_name (str):  The name of the column to limit the categories on\n",
    "                 num_categories (int):  The maximum number of unique values to retain in 'column_name'\n",
    "            '''\n",
    "            selected = self.df[column_name].value_counts()[:num_categories].index.tolist()\n",
    "            self.df = self.df[self.df[column_name].isin(selected)]\n",
    "            #self.updateCodeIdVariables()\n",
    "\n",
    "        def replaceValueWithStringInColumn(self, column_name, replace_value, with_string):\n",
    "            self.dfDecisionTree[column_name] = [\n",
    "                with_string if str(x) == '{}'.format(replace_value) else x \n",
    "                for x in self.dfDecisionTree[column_name]]  # Replace zeros in col='disposition' with 'Unknown'\n",
    "\n",
    "        def checkForNumericValueInColumn(self, columnName):\n",
    "            for index, value in enumerate(self.dfDecisionTree[columnName]):\n",
    "                if type(value) == int:\n",
    "                    if 'Treatment_Date' in self.dfDecisionTree.columns:\n",
    "                        print('{}: Found int={} at {} - {}'.format(\n",
    "                            columnName, value, index, dfDecisionTree['Treatment_Date'].iloc[index]))\n",
    "                    else:\n",
    "                        print('{}: Found int={} at {}'.format(columnName, value, index))\n",
    "\n",
    "        def createOnHotEncodedDataframe(df):\n",
    "            '''\n",
    "            Take columns that are objects and turn them into multiple one-hot columns.\n",
    "\n",
    "            Args:\n",
    "                df    (pd.DataFrame):  The dataframe to convert to a one-hot dataframe\n",
    "\n",
    "            Returns:\n",
    "                dfOneHot (pd.DataFrame):  A dataframe with the original objects replaced with one-hot versions.\n",
    "\n",
    "\n",
    "            Example dataframe:\n",
    "\n",
    "                Cost(dollars)  Item\n",
    "                2              'Baseball'\n",
    "                5              'Baseball Glove'\n",
    "                7              'Helmet'\n",
    "\n",
    "            Will become a dataframe similar to:\n",
    "\n",
    "                Cost(dollars)  ('Item', 'Baseball')    ('Item', 'Baseball Glove')  ('Item', 'Helmet)\n",
    "                2              1                       0                           0\n",
    "                5              0                       1                           0\n",
    "                7              0                       0                           1\n",
    "\n",
    "            By making a tuple for the column header it is easy to determine the variable that the one-hot\n",
    "            column represents.\n",
    "            '''\n",
    "            dfOneHot = df.copy()\n",
    "\n",
    "            updateFreq = 100\n",
    "            print('Dots are printed every {} translations during one-hot transformation'.format(updateFreq))\n",
    "\n",
    "            for col in df.columns:\n",
    "                if df[col].dtype == object:\n",
    "                    print('Transforming {:20s}'.format(col), end='\\t')\n",
    "\n",
    "                    unique = pd.unique(df[col].sort_values(ascending=True))\n",
    "                    nUnique = len(unique)\n",
    "                    print('nUnique={}'.format(nUnique), end='\\t')\n",
    "\n",
    "                    updateIndex = updateFreq\n",
    "                    updateNext = updateFreq\n",
    "\n",
    "                    for index, value in enumerate(unique):\n",
    "                        if index == updateIndex:\n",
    "                            updateIndex += updateFreq\n",
    "                            updateNext += updateFreq\n",
    "                            print('.', end='')\n",
    "\n",
    "                        dfOneHot[(col, value)] = (dfOneHot[col] == value).astype(int)\n",
    "                    dfOneHot.drop(columns=[col], inplace=True)\n",
    "                    print('\\tcomplete')\n",
    "            return dfOneHot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-639e359426c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpruner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFramePruner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_prune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0moutput_choice\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_output_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_output_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdecisionTree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWorkingDecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_choice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpruner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-5c5292a29614>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df, output_choice, dataframe_pruner)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Treatment_Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfDecisionTree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslateCodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplaceValueWithStringInColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Product_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Zero'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Keep the zero.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Boston University/MET_CS677_DataScienceWithPython/Project/neiss_backend.py\u001b[0m in \u001b[0;36mtranslateCodes\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranslateCodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNeiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT_CATEGORY_TRANSLATOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   4261\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4262\u001b[0m             \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4263\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4264\u001b[0m         )\n\u001b[1;32m   4265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   6680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6681\u001b[0m             return self.replace(\n\u001b[0;32m-> 6682\u001b[0;31m                 \u001b[0mto_replace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6683\u001b[0m             )\n\u001b[1;32m   6684\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   4261\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4262\u001b[0m             \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4263\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4264\u001b[0m         )\n\u001b[1;32m   4265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   6700\u001b[0m                                 \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6701\u001b[0m                                 \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6702\u001b[0;31m                                 \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6703\u001b[0m                             )\n\u001b[1;32m   6704\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3470\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3471\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3472\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3474\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3548\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3549\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3550\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3552\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3381\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3382\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m                     \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mDelete\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \"\"\"\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(arr, obj, axis)\u001b[0m\n\u001b[1;32m   4422\u001b[0m         \u001b[0mkeep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4423\u001b[0m         \u001b[0mslobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4424\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if True == Includes.DecisionTree:\n",
    "    df = neiss.getDataFrame()\n",
    "    #max_output_rows = 100000\n",
    "    max_output_rows = len(df) // 4\n",
    "    pruner = DataFramePruner(dict_prune={output_choice : 10}, max_output_rows=max_output_rows)\n",
    "        \n",
    "    decisionTree = WorkingDecisionTree(df, output_choice, pruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.DecisionTree:\n",
    "    render_name='neiss_full'\n",
    "    graph_viz=False\n",
    "    decisionTree.fullTestTrainAccuracy(graph_viz=graph_viz, render_name=render_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.DecisionTree:\n",
    "    if True == graph_viz:\n",
    "        !open '{}.pdf'.format(render_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***** \n",
    "- Now with 70% training set, 30% testing set\n",
    "- ***** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.DecisionTree:\n",
    "    bu_id = 7286\n",
    "    render_name='neiss_70_30_split'\n",
    "    graph_viz=False\n",
    "    decisionTree.splitTestTrainAccuracy(graph_viz=graph_viz, render_name=render_name, test_size=0.3, random_state=bu_id)                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == Includes.DecisionTree:\n",
    "    if True == graph_viz:\n",
    "        !open '{}.pdf'.format(render_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
